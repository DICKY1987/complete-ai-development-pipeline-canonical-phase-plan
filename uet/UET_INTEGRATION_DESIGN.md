---
doc_id: DOC-GUIDE-UET-INTEGRATION-DESIGN-1653
---

# UET Framework Selective Integration - Design Document

**Status**: Active Implementation
**Decision**: Option A - Selective Integration
**Timeline**: 3-4 weeks
**Risk Level**: Low
**Created**: 2025-11-22

---

## Executive Summary

This document outlines the **selective integration** of the Universal Execution Templates (UET) Framework into the existing AI Development Pipeline. We adopt three high-value components while preserving existing orchestration and state management.

**Adopted Components:**
1. ✅ **Bootstrap System** - Auto-project configuration
2. ✅ **Resilience Module** - Circuit breakers & retry logic
3. ✅ **Progress Tracking** - Real-time monitoring

**Preserved Components:**
- Existing orchestrator (`core/engine/orchestrator.py`)
- State management (`core/state/`)
- Error detection pipeline (`error/`)
- Workstream schemas (extended, not replaced)

---

## Phase 1: Foundation (Week 1-2)

### 1.1 Module Integration Structure

**New directory structure:**
```
core/
├── bootstrap_uet/           # NEW: UET bootstrap system
│   ├── __init__.py
│   ├── discovery.py         # Project scanner
│   ├── selector.py          # Profile selector
│   ├── generator.py         # Artifact generator
│   ├── validator.py         # Bootstrap validator
│   └── orchestrator.py      # Bootstrap orchestrator
├── engine/
│   ├── resilience/          # NEW: UET resilience patterns
│   │   ├── __init__.py
│   │   ├── circuit_breaker.py
│   │   ├── retry.py
│   │   └── resilient_executor.py
│   ├── monitoring/          # NEW: UET progress tracking
│   │   ├── __init__.py
│   │   ├── progress_tracker.py
│   │   └── run_monitor.py
│   └── ... (existing files)
└── state/
    └── ... (existing files)
```

### 1.2 Schema Extensions

**Add to `schema/` directory:**
- `project_profile.v1.json` - UET project profile schema
- `router_config.v1.json` - Tool routing configuration
- `migrations/002_uet_foundation.sql` - Database migration

**Database additions (non-breaking):**
```sql
-- New tables for UET integration
CREATE TABLE IF NOT EXISTS workers (
  worker_id TEXT PRIMARY KEY,
  adapter_type TEXT NOT NULL,
  state TEXT NOT NULL CHECK(state IN ('IDLE', 'BUSY', 'TERMINATED')),
  current_task_id TEXT,
  heartbeat_at TEXT,
  spawned_at TEXT NOT NULL,
  FOREIGN KEY (current_task_id) REFERENCES steps(id)
);

CREATE TABLE IF NOT EXISTS events (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  event_type TEXT NOT NULL,
  worker_id TEXT,
  task_id TEXT,
  timestamp TEXT NOT NULL,
  payload JSON,
  FOREIGN KEY (worker_id) REFERENCES workers(worker_id),
  FOREIGN KEY (task_id) REFERENCES steps(id)
);

CREATE TABLE IF NOT EXISTS cost_tracking (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  step_id TEXT NOT NULL,
  input_tokens INTEGER DEFAULT 0,
  output_tokens INTEGER DEFAULT 0,
  estimated_cost_usd REAL DEFAULT 0.0,
  timestamp TEXT NOT NULL,
  FOREIGN KEY (step_id) REFERENCES steps(id)
);

CREATE INDEX idx_events_timestamp ON events(timestamp);
CREATE INDEX idx_events_type ON events(event_type);
```

### 1.3 Configuration Files

**Generated by bootstrap:**
- `PROJECT_PROFILE.yaml` - Auto-generated project configuration
- `router_config.json` - Tool routing and capabilities
- `.uet/config.json` - UET runtime settings

---

## Phase 2: Bootstrap Integration (Week 1)

### 2.1 Bootstrap Script Enhancement

**Update `scripts/bootstrap.ps1`:**

```powershell
# Existing bootstrap logic...

# NEW: UET Bootstrap Integration
Write-Host "`n==> Running UET Bootstrap Analysis..." -ForegroundColor Cyan

$pythonCmd = Get-Command python -ErrorAction SilentlyContinue
if (-not $pythonCmd) {
    Write-Warning "Python not found, skipping UET bootstrap"
} else {
    python -m core.bootstrap_uet.orchestrator . --quiet
    if ($LASTEXITCODE -eq 0) {
        Write-Host "   OK - PROJECT_PROFILE.yaml generated" -ForegroundColor Green
        Write-Host "   OK - router_config.json generated" -ForegroundColor Green
    } else {
        Write-Warning "UET bootstrap failed (non-critical)"
    }
}

# Existing validation logic...
```

### 2.2 Bootstrap Orchestrator Adapter

**Create `core/bootstrap_uet/__init__.py`:**

```python
"""
UET Bootstrap Integration

Wraps UET bootstrap system for seamless integration with existing pipeline.
"""

from pathlib import Path
from typing import Dict, Optional, Any

# Import UET bootstrap modules
from .discovery import ProjectScanner
from .selector import ProfileSelector
from .generator import ArtifactGenerator
from .validator import BootstrapValidator

__all__ = [
    'bootstrap_project',
    'ProjectScanner',
    'ProfileSelector',
    'ArtifactGenerator',
    'BootstrapValidator'
]

def bootstrap_project(
    project_path: str = ".",
    output_dir: Optional[str] = None,
    quiet: bool = False
) -> Dict[str, Any]:
    """
    Bootstrap the current project with UET framework.

    Args:
        project_path: Path to project root (default: current directory)
        output_dir: Output directory for artifacts (default: project_path)
        quiet: Suppress output (default: False)

    Returns:
        Bootstrap result with status and generated files
    """
    from .orchestrator import BootstrapOrchestrator

    orchestrator = BootstrapOrchestrator(project_path, output_dir)
    result = orchestrator.run()

    if not quiet:
        _print_bootstrap_summary(result)

    return result

def _print_bootstrap_summary(result: Dict[str, Any]) -> None:
    """Print human-readable bootstrap summary."""
    if result.get('success'):
        print("\n✅ UET Bootstrap Complete!")
        print(f"  Domain: {result.get('domain', 'unknown')}")
        print(f"  Profile: {result.get('profile_id', 'unknown')}")
        print(f"  Files: {', '.join(result.get('generated_files', []))}")
    else:
        print(f"\n❌ Bootstrap Failed: {result.get('error', 'unknown error')}")
```

### 2.3 CLI Integration

**Create `scripts/bootstrap_uet.py`:**

```python
#!/usr/bin/env python3
"""
UET Bootstrap CLI

Standalone tool for running UET bootstrap on any project.
"""

import argparse
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.bootstrap_uet import bootstrap_project

def main():
    parser = argparse.ArgumentParser(
        description="Bootstrap project with UET Framework"
    )
    parser.add_argument(
        'project_path',
        nargs='?',
        default='.',
        help='Path to project root (default: current directory)'
    )
    parser.add_argument(
        '--output-dir',
        help='Output directory for generated files (default: project_path)'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='Suppress output'
    )
    parser.add_argument(
        '--validate-only',
        action='store_true',
        help='Validate existing artifacts without regeneration'
    )

    args = parser.parse_args()

    try:
        result = bootstrap_project(
            args.project_path,
            args.output_dir,
            args.quiet
        )

        sys.exit(0 if result.get('success') else 1)

    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
```

---

## Phase 3: Resilience Integration (Week 2)

### 3.1 Resilient Tool Wrapper

**Enhance `core/engine/tools.py`:**

```python
"""
Tool invocation with UET resilience patterns.
"""

from typing import Any, Callable, Dict, Optional
from core.engine.resilience import ResilientExecutor, CircuitBreakerOpen, RetryExhausted

# Global resilient executor instance
_executor: Optional[ResilientExecutor] = None

def _get_executor() -> ResilientExecutor:
    """Get or create resilient executor singleton."""
    global _executor
    if _executor is None:
        _executor = ResilientExecutor()
        # Register default tool configurations
        _executor.register_tool(
            "aider",
            max_retries=3,
            failure_threshold=5,
            recovery_timeout=60,
            base_delay=1.0
        )
        _executor.register_tool(
            "codex",
            max_retries=2,
            failure_threshold=3,
            recovery_timeout=30,
            base_delay=0.5
        )
        _executor.register_tool(
            "pytest",
            max_retries=1,
            failure_threshold=2,
            recovery_timeout=15,
            base_delay=0.5
        )
    return _executor

def invoke_tool(
    tool_name: str,
    operation: Callable[[], Any],
    timeout: Optional[int] = None
) -> Any:
    """
    Invoke tool with resilience patterns (circuit breaker + retry).

    Args:
        tool_name: Tool identifier (aider, codex, pytest, etc.)
        operation: Callable that performs the tool operation
        timeout: Optional timeout in seconds

    Returns:
        Result from operation

    Raises:
        CircuitBreakerOpen: If circuit is open
        RetryExhausted: If all retries failed
    """
    executor = _get_executor()

    try:
        return executor.execute(tool_name, operation)
    except CircuitBreakerOpen:
        # Log and escalate
        from error.engine.error_pipeline_service import ErrorPipelineService
        svc = ErrorPipelineService()
        svc.log_error(
            error_type="E_CIRCUIT_BREAKER_OPEN",
            message=f"Circuit breaker open for tool: {tool_name}",
            metadata={"tool": tool_name}
        )
        raise
    except RetryExhausted as e:
        # Log and escalate
        from error.engine.error_pipeline_service import ErrorPipelineService
        svc = ErrorPipelineService()
        svc.log_error(
            error_type="E_RETRY_EXHAUSTED",
            message=f"All retries exhausted for tool: {tool_name}",
            metadata={"tool": tool_name, "attempts": e.attempts}
        )
        raise

def get_tool_health(tool_name: str) -> Dict[str, Any]:
    """Get health status of a tool's circuit breaker."""
    executor = _get_executor()
    return executor.get_tool_state(tool_name)

def reset_tool_circuit(tool_name: str) -> None:
    """Manually reset a tool's circuit breaker."""
    executor = _get_executor()
    state = executor.get_tool_state(tool_name)
    if state and state.get('circuit_breaker'):
        state['circuit_breaker'].reset()
```

### 3.2 Adapter Integration

**Update `core/engine/adapters/aider.py`:**

```python
from core.engine.tools import invoke_tool

class AiderAdapter:
    def execute(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Execute Aider with resilience wrapper."""

        def operation():
            # Existing Aider execution logic
            return self._execute_aider(request)

        # Wrap with resilience
        return invoke_tool("aider", operation)

    def _execute_aider(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Original Aider execution logic (unchanged)."""
        # ... existing implementation ...
        pass
```

### 3.3 Health Monitoring CLI

**Create `scripts/tool_health.py`:**

```python
#!/usr/bin/env python3
"""
Tool Health Monitor

Check circuit breaker status for all registered tools.
"""

import sys
from pathlib import Path
from tabulate import tabulate

sys.path.insert(0, str(Path(__file__).parent.parent))

from core.engine.tools import _get_executor

def main():
    executor = _get_executor()

    # Get all registered tools
    tools = ['aider', 'codex', 'pytest']

    rows = []
    for tool in tools:
        state = executor.get_tool_state(tool)
        if state:
            rows.append([
                tool,
                state.get('state', 'UNKNOWN'),
                state.get('failure_count', 0),
                state.get('success_count', 0),
                f"{state.get('error_rate', 0):.1%}"
            ])

    headers = ['Tool', 'Circuit', 'Failures', 'Successes', 'Error Rate']
    print(tabulate(rows, headers=headers, tablefmt='grid'))

if __name__ == '__main__':
    main()
```

---

## Phase 4: Progress Tracking (Week 3)

### 4.1 Orchestrator Enhancement

**Update `core/engine/orchestrator.py`:**

```python
from core.engine.monitoring import ProgressTracker, RunMonitor

class Orchestrator:
    def __init__(self, db=None):
        self.db = db or get_db()
        self.progress_tracker: Optional[ProgressTracker] = None
        self.run_monitor = RunMonitor(str(self.db.db_path))

    def execute_workstream(self, workstream_id: str, run_id: str) -> Dict[str, Any]:
        """Execute workstream with progress tracking."""

        # Load workstream
        ws = self._load_workstream(workstream_id)
        total_steps = len(ws.get('steps', []))

        # Initialize progress tracker
        self.progress_tracker = ProgressTracker(run_id, total_steps)
        self.progress_tracker.start()

        try:
            for step in ws['steps']:
                # Start step
                self.progress_tracker.start_task(step['id'])

                # Execute step (existing logic)
                start_time = time.time()
                result = self._execute_step(step)
                duration = time.time() - start_time

                # Complete step
                if result.get('success'):
                    self.progress_tracker.complete_task(step['id'], duration)
                else:
                    self.progress_tracker.fail_task(step['id'], result.get('error'))

                # Periodic snapshot
                if step['id'] % 5 == 0:
                    snapshot = self.progress_tracker.get_snapshot()
                    print(f"Progress: {snapshot.completion_percent:.1f}% "
                          f"(ETA: {snapshot.estimated_completion})")

        finally:
            # Final snapshot
            snapshot = self.progress_tracker.get_snapshot()
            return {
                'success': snapshot.failed_tasks == 0,
                'completed': snapshot.completed_tasks,
                'failed': snapshot.failed_tasks,
                'duration': snapshot.elapsed_seconds,
                'completion_percent': snapshot.completion_percent
            }
```

### 4.2 Real-Time Progress Display

**Create `scripts/monitor_run.py`:**

```python
#!/usr/bin/env python3
"""
Real-Time Run Monitor

Display live progress for active runs.
"""

import sys
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from core.engine.monitoring import RunMonitor

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--run-id', required=True)
    parser.add_argument('--refresh', type=int, default=5)
    args = parser.parse_args()

    monitor = RunMonitor()

    try:
        while True:
            metrics = monitor.get_run_metrics(args.run_id)

            print(f"\033[2J\033[H")  # Clear screen
            print(f"Run: {args.run_id}")
            print(f"Status: {metrics.status}")
            print(f"Progress: {metrics.completed_steps}/{metrics.total_steps}")
            print(f"Events: {metrics.total_events}")
            print(f"\nRefreshing every {args.refresh}s... (Ctrl+C to stop)")

            if metrics.status in ['completed', 'failed']:
                print("\n✅ Run finished!")
                break

            time.sleep(args.refresh)

    except KeyboardInterrupt:
        print("\n\nMonitoring stopped.")

if __name__ == '__main__':
    main()
```

---

## Phase 5: Testing & Validation (Week 4)

### 5.1 Integration Tests

**Create `tests/uet_integration/test_bootstrap.py`:**

```python
"""Test UET bootstrap integration."""

import pytest
from pathlib import Path
from core.bootstrap_uet import bootstrap_project

def test_bootstrap_current_project():
    """Test bootstrapping the pipeline itself."""
    result = bootstrap_project(".", quiet=True)

    assert result['success']
    assert result['domain'] in ['software-dev', 'mixed']
    assert result['profile_id'] in ['software-dev-python', 'generic']
    assert Path('PROJECT_PROFILE.yaml').exists()
    assert Path('router_config.json').exists()

def test_generated_profile_valid():
    """Test generated profile validates against schema."""
    import yaml
    import jsonschema

    with open('PROJECT_PROFILE.yaml') as f:
        profile = yaml.safe_load(f)

    with open('schema/project_profile.v1.json') as f:
        schema = json.load(f)

    jsonschema.validate(profile, schema)
```

**Create `tests/uet_integration/test_resilience.py`:**

```python
"""Test resilience integration."""

import pytest
from core.engine.tools import invoke_tool, get_tool_health
from core.engine.resilience import CircuitBreakerOpen, RetryExhausted

def test_circuit_breaker_opens_on_failures():
    """Test circuit breaker opens after threshold."""

    def failing_operation():
        raise Exception("Simulated failure")

    # Should retry and eventually exhaust
    with pytest.raises(RetryExhausted):
        invoke_tool("test_tool", failing_operation)

    # Check circuit state
    health = get_tool_health("test_tool")
    assert health['failure_count'] >= 3

def test_successful_execution_resets_circuit():
    """Test successful execution resets failure count."""

    def successful_operation():
        return {"status": "ok"}

    result = invoke_tool("test_tool", successful_operation)
    assert result['status'] == 'ok'

    health = get_tool_health("test_tool")
    assert health['success_count'] > 0
```

### 5.2 Performance Benchmarks

**Create `tests/uet_integration/test_performance.py`:**

```python
"""Performance tests for UET integration."""

import pytest
import time
from core.engine.monitoring import ProgressTracker

def test_progress_tracker_overhead():
    """Ensure progress tracking adds < 50ms overhead per task."""

    tracker = ProgressTracker("test-run", total_tasks=100)
    tracker.start()

    start = time.perf_counter()
    for i in range(100):
        tracker.start_task(f"task-{i}")
        tracker.complete_task(f"task-{i}", duration=0.001)
    elapsed = time.perf_counter() - start

    # Total overhead should be < 5 seconds for 100 tasks (50ms/task)
    assert elapsed < 5.0
```

---

## Rollout Plan

### Week 1: Foundation
- ✅ Copy UET modules to `core/bootstrap_uet/`, `core/engine/resilience/`, `core/engine/monitoring/`
- ✅ Add UET schemas to `schema/`
- ✅ Create database migration `schema/migrations/002_uet_foundation.sql`
- ✅ Update `scripts/bootstrap.ps1` with UET integration
- ✅ Test bootstrap on pipeline itself

### Week 2: Resilience
- ✅ Wrap existing tool invocations with `ResilientExecutor`
- ✅ Update all adapters (Aider, Codex, Tests, Git)
- ✅ Create health monitoring CLI
- ✅ Test circuit breaker behavior
- ✅ Document configuration options

### Week 3: Progress Tracking
- ✅ Instrument orchestrator with `ProgressTracker`
- ✅ Add progress snapshots to execution logs
- ✅ Create real-time monitoring CLI
- ✅ Test with actual workstream execution
- ✅ Gather baseline metrics

### Week 4: Validation
- ✅ Write integration tests (bootstrap, resilience, monitoring)
- ✅ Run full pipeline test suite (ensure no regressions)
- ✅ Performance benchmarking
- ✅ Update documentation
- ✅ Prepare Phase 2 planning (if proceeding with full UET adoption)

---

## Success Metrics

### Quantitative
- ✅ **Bootstrap Success Rate**: > 95% of projects bootstrap correctly
- ✅ **Circuit Breaker Effectiveness**: < 5% false positives
- ✅ **Progress Tracking Overhead**: < 50ms per task
- ✅ **Test Coverage**: > 80% for UET integration code
- ✅ **Zero Regressions**: All existing tests pass

### Qualitative
- ✅ **Developer Experience**: Simpler project setup (no manual config)
- ✅ **Reliability**: Fewer tool invocation failures
- ✅ **Observability**: Real-time progress visibility
- ✅ **Maintainability**: Clean integration with existing codebase

---

## Risk Mitigation

### High Risks
1. **Schema Migration Breaks Existing DB**
   - **Mitigation**: Idempotent migration script, backup before migration
   - **Test**: Run migration on copy of production DB
   - **Rollback**: Keep old schema, disable UET features

2. **Resilience Wrapper Introduces Bugs**
   - **Mitigation**: Phased rollout (one tool at a time)
   - **Test**: Shadow mode (log but don't act on circuit breaker)
   - **Rollback**: Feature flag to disable resilience

### Medium Risks
3. **Progress Tracking Performance Impact**
   - **Mitigation**: Async event emission, batched writes
   - **Test**: Benchmark with 100+ task workstreams
   - **Rollback**: Make progress tracking optional

4. **Bootstrap Generates Invalid Configs**
   - **Mitigation**: Validation step after generation
   - **Test**: Bootstrap on diverse project types
   - **Rollback**: Manual config option

---

## Future Enhancements (Post-Integration)

### Phase 2 Candidates (If Option A succeeds):
1. **Adapter Migration** - Replace custom adapters with UET `AdapterRegistry`
2. **Scheduler Enhancement** - Add wave-based parallel execution
3. **Cost Tracking** - Integrate token/cost monitoring
4. **Context Management** - Auto-pruning for large contexts

### Phase 3 Candidates (Full UET Adoption):
1. **Worker Pool** - Multi-worker orchestration
2. **Event Bus** - Centralized event logging
3. **Merge Strategy** - Integration worker for parallel workstreams
4. **Crash Recovery** - Checkpoint/restore system

---

## Documentation Updates

### New Files
- ✅ `docs/UET_INTEGRATION_DESIGN.md` (this file)
- ✅ `docs/UET_BOOTSTRAP_GUIDE.md` - User guide for bootstrap
- ✅ `docs/UET_RESILIENCE_CONFIG.md` - Circuit breaker configuration
- ✅ `docs/UET_MONITORING_GUIDE.md` - Progress tracking usage

### Updated Files
- ✅ `README.md` - Add UET integration section
- ✅ `QUICK_START.md` - Update bootstrap instructions
- ✅ `AGENTS.md` - Add UET import patterns
- ✅ `docs/ENGINE_QUICK_REFERENCE.md` - Add resilience usage

---

## Appendix: File Inventory

### New Files (Est. 15-20)
**Core Modules:**
- `core/bootstrap_uet/*.py` (5 files)
- `core/engine/resilience/*.py` (3 files)
- `core/engine/monitoring/*.py` (2 files)

**Scripts:**
- `scripts/bootstrap_uet.py`
- `scripts/tool_health.py`
- `scripts/monitor_run.py`

**Tests:**
- `tests/uet_integration/test_bootstrap.py`
- `tests/uet_integration/test_resilience.py`
- `tests/uet_integration/test_monitoring.py`
- `tests/uet_integration/test_performance.py`

**Schemas:**
- `schema/project_profile.v1.json`
- `schema/router_config.v1.json`
- `schema/migrations/002_uet_foundation.sql`

### Modified Files (Est. 8-10)
- `scripts/bootstrap.ps1`
- `core/engine/tools.py`
- `core/engine/orchestrator.py`
- `core/engine/adapters/aider.py`
- `core/engine/adapters/codex.py`
- `README.md`
- `QUICK_START.md`
- `AGENTS.md`

---

**Next Steps**: Begin Week 1 implementation with module copying and bootstrap integration.
