---
doc_id: DOC-PAT-UTE-UNIVERSAL-PHASE-SPECIFICATION-TXT-001
---

# 1. UNIVERSAL PHASE SPECIFICATION

*(The “What”) – Non-Negotiable Requirements for Every Development Phase*

This specification defines the mandatory structure and gates for **all** development phases executed by autonomous AI agents.

If an AI cannot populate **every required field** and satisfy **every gate** defined here, it **MUST NOT** proceed with that phase.

---

## 1.1 Phase Identity & Metadata

Every phase **MUST** be represented as a structured record (YAML/JSON) with the following minimum fields:

* `phase_id`

  * Example: `"PH-00"`, `"PH-01A"`, `"PH-01B"`, `"PH-02"`
  * Uniquely identifies the phase in the global plan.

* `workstream_id`

  * Example: `"ws-22-pipeline-plus-phase0-schema"`, `"ws-23-pipeline-plus-phase1a-task-queue"`
  * **MUST** match the corresponding `workstreams/*.json` ID.

* `title`

  * Short, single-focus description.
  * Example: `"Pre-Flight & Schema Setup"`, `"Task Queue Management"`, `"Audit & Telemetry Foundation"`.

* `objective`

  * One **tight**, atomic goal in plain language.
  * Example:

    * `"Create and validate the .tasks/.ledger/.runs directory structure and baseline schema migration for patch support."`
    * `"Implement file-based task queue plus tests for enqueue/dequeue lifecycle."`

* `phase_type`

  * Enumerated: `implementation | refactor | integration | migration | validation_only | documentation_only`.

* `parallel_group` (optional)

  * For phases that may run concurrently.
  * Example:

    * `phase_id: PH-01A, parallel_group: "G1"`
    * `phase_id: PH-01B, parallel_group: "G1"`
  * Used to encode patterns like **Phase 0 → Phase 1A & 1B in parallel**.

---

## 1.2 Dependencies & Ordering

Every phase **MUST** explicitly define dependency ordering:

* `depends_on` (list of `workstream_id`s or `phase_id`s)

  * Example: `["ws-22-pipeline-plus-phase0-schema"]`.

* `may_run_parallel_with` (optional)

  * Example: `["ws-24-pipeline-plus-phase1b-audit"]`.

Rules:

1. The AI **MUST NOT** start a phase until **all** `depends_on` are in a **programmatically verified “done”** state.
2. Parallelization (e.g., **PH-01A & PH-01B**) is allowed **only** when:

   * All shared dependencies (e.g., PH-00) are verified complete.
   * File scopes do not overlap except for explicitly declared shared read-only resources.

---

## 1.3 File Scope Declaration (Create / Modify / Read-Only)

Each phase **MUST** declare a precise file scope; this drives patch validation and isolation:

```yaml
file_scope:
  create:
    - "core/state/task_queue.py"
    - "core/state/audit_logger.py"
    - "tests/test_task_queue.py"
    - "tests/test_audit_logger.py"
  modify:
    - "scripts/SubmitTask.ps1"
    - "core/db.py"
  read_only:
    - "schema/workstream.schema.json"
    - "config/router.config.yaml"
    - "tests/conftest.py"
```

Requirements:

1. The AI **MUST** restrict all edits to `create` + `modify`.
2. Files in `read_only` **MUST NOT** be modified (only read for context).
3. Any patch touching paths outside `create` + `modify` is a **scope violation** and **MUST** be rejected by validation gates.
4. For phases that create directories (e.g., **Phase 0**), the directory hierarchy (e.g., `.tasks/inbox`, `.ledger/patches`, `.runs`) **MUST** be explicitly enumerated in `file_scope.create`.

---

## 1.4 Tooling & Environment Specification

Each phase **MUST** declare the tools and environment assumptions it relies on:

```yaml
tools:
  primary_language: "python"
  secondary_language: "powershell"
  ai_tools:
    - "aider"
  test_runners:
    - "python -m pytest -q"
  static_checkers:
    - "ruff check"
  shell:
    preferred: "pwsh"
    alternatives: ["bash"]
```

Rules:

1. The AI **MUST** use these declared commands to validate work (no ad-hoc, undocumented commands as the only proof).
2. If the environment is missing a required tool, the phase **MUST** invoke self-healing procedures (e.g., install via `pip`, `winget`, etc.) **before** execution, or fail fast.

---

## 1.5 Pre-Flight Check (Mandatory for Every Phase)

Before executing any implementation steps, the AI **MUST** perform a **Pre-Flight Check** and **MUST NOT** proceed if any check fails.

Minimum Pre-Flight checklist:

1. **Git & Worktree State**

   * `git status --porcelain` confirms:

     * No unexpected uncommitted changes, **OR**
     * All changes are explicitly associated with the current workstream.
   * For non-trivial phases:

     * A dedicated worktree exists: `.worktrees/{workstream_id}/`.
     * Current working directory is the correct worktree.

2. **Repository Location**

   * Confirm current directory matches declared `repo_path`.
   * E.g., path contains `Complete AI Development Pipeline – Canonical Phase Plan` when expected.

3. **Architecture Baseline**

   * For phases **after PH-00**:

     * `.tasks/inbox`, `.tasks/running`, `.tasks/done`, `.tasks/failed` exist.
     * `.ledger/patches/` exists.
     * `.runs/` exists.
     * `schema/migrations/001_add_patches_table.sql` exists.
     * `config/router.config.yaml` exists.
   * If missing, the AI **MUST** either:

     * Re-run Phase 0, or
     * Self-heal by creating these artifacts according to the standard schema.

4. **Environment & Virtualenv**

   * Python version meets or exceeds required version.
   * Virtual environment exists and is activatable (or explicit choice not to use venv).
   * Critical dependencies for this phase (e.g., `filelock`, `ulid-py`) are installed.

5. **Workstream Definition Exists**

   * Corresponding `workstreams/{workstream_id}.json` exists.
   * Validates against `schema/workstream.schema.json`.

Pre-Flight output:

* Pre-flight **MUST** be captured as CLI output showing all checks and whether they passed.
* If any check fails:

  * The AI **MUST** attempt self-healing (see Operator Standard).
  * If self-healing fails, the phase is **blocked** and **MUST** be marked as such, **NOT** “done”.

---

## 1.6 Programmatic Acceptance Tests (Mandatory)

Every phase **MUST** define acceptance tests that can be evaluated programmatically through CLI commands.

Minimum structure:

```yaml
acceptance:
  powershell:
    - name: "Phase 0 directories exist"
      command: >
        Write-Host "=== Phase 0 Acceptance Tests ===";
        @('.tasks\inbox', '.tasks\running', '.tasks\done', '.tasks\failed', '.ledger\patches', '.runs') |
          ForEach-Object { if (-not (Test-Path "$_\.gitkeep")) { throw "Missing $_\.gitkeep" } }
    - name: "Migration file exists"
      command: >
        if (-not (Test-Path "schema\migrations\001_add_patches_table.sql")) { throw "Missing migration" }
  python:
    - name: "Phase 1 queue & audit tests"
      command: "python -m pytest -q tests/test_task_queue.py tests/test_audit_logger.py"
      success_pattern: "passed"
      max_failures: 0
```

Rules:

1. **Conversation text is never sufficient.**

   * “Looks good”, “Seems complete”, “I have implemented X” **do not count** as acceptance.
2. The AI **MUST** run all declared acceptance commands.
3. A phase can be marked **done** **only if:**

   * All acceptance commands exit with **code 0**, and
   * Their outputs contain the expected success patterns (e.g., `"20 passed"`).
4. If any acceptance command fails:

   * The phase **MUST** remain **not done**.
   * The AI **MUST** enter a self-healing loop (see Operator Standard).

---

## 1.7 Output Artifacts & Logging

Each phase **MUST** produce:

* A **patch artifact** for any code changes:

  * Stored in `.ledger/patches/{workstream_id}-{run_id}.patch`.
  * Metadata recorded in the patches table (`schema/migrations/001_add_patches_table.sql` schema).
* Associated **audit entries**:

  * `.runs/audit.jsonl` entries describing:

    * `event_type` (e.g., `patch_captured`, `patch_validated`, `completed`).
    * `task_id` / `ws_id`.
    * Tool used.
* Test output logs:

  * Either stored directly or retrievable via JSONL logs.

No phase is **complete** until these artifacts exist and pass their validations.

---

## 1.8 Phase Completion Gate

A phase is **ONLY** in state `done` when:

1. All `depends_on` phases are verified `done`.
2. Pre-Flight Check succeeds (or is successfully self-healed and re-verified).
3. All implementation steps run within the declared file scope & isolation rules.
4. **All** acceptance tests pass with exit code 0 and valid success output.
5. Patch and audit artifacts exist, are stored, and validated.

If any of these criteria are missing, the AI **MUST** treat the phase as **incomplete** and **MUST NOT** promote it to `done`.

---

# 2. OPERATOR EXECUTION STANDARD

*(The “How”) – Rules of Engagement for Autonomous AI Agents*

This standard governs **how** AI agents must behave during execution. It encodes the **Operator Mindset**: run commands, inspect reality, self-heal, and validate.

Any AI that cannot comply with these rules **MUST NOT** operate in this system.

---

## 2.1 Ground Truth via CLI (Never “Vibes”)

1. The AI **MUST** treat CLI outputs (exit codes + stdout/stderr) as the **only ground truth**.
2. The AI **MUST NOT**:

   * Infer success based purely on reasoning or prior expectations.
   * Declare completion because “it looks correct” or “should be fine”.
3. Before claiming success, the AI **MUST**:

   * Run explicit verification commands:

     * Examples:

       * `git status --short`
       * `python -m pytest -q tests/test_*.py`
       * `Test-Path` checks for required files/dirs.
   * Inspect and interpret these outputs.

If CLI evidence conflicts with the AI’s internal expectations, **CLI wins**.

---

## 2.2 Self-Healing Behavior (Standard Fixes Without Permission)

The AI is expected to operate as an **autonomous operator**, not a passive suggestion engine.

### 2.2.1 When a Tool Under-Delivers

If a tool (e.g., Aider) claims success but:

* Required directories/files are **missing**, or
* Git shows **no changes** where changes were expected,

the AI **MUST**:

1. Detect the discrepancy via:

   * `Test-Path` (PowerShell)
   * `ls` / `Get-ChildItem`
   * `git diff --name-only`
2. Take direct corrective action, for example:

   * Create directories:

     * `New-Item -ItemType Directory -Force -Path '.tasks\inbox'`
   * Create files with canonical contents using:

     * PowerShell `Set-Content` / `@"... "@` blocks.
     * `python -c "..."` writes.
3. Re-run acceptance tests after fixes.

The AI **MUST NOT** ask the user:

* “Would you like me to create these directories?”
* “Should I fix this missing file?”

Standard, deterministic fixes **MUST** be applied autonomously.

### 2.2.2 When Tests or Commands Fail

If:

* `pytest` fails,
* A CLI command times out, or
* Static checks fail,

the AI **MUST**:

1. Inspect failure output.
2. Identify the minimal code patch needed.
3. Apply patch (preferably via patch workflow).
4. Re-run the failing command.
5. Repeat until:

   * Acceptance passes, or
   * Circuit breakers (attempt/oscillation thresholds) trip.

The AI **MUST NOT** treat a failing test as “advisory”.

---

## 2.3 Isolation via Worktrees & Patches

### 2.3.1 Worktree Requirement

For all non-trivial modifications (anything beyond a trivial single-file doc edit):

1. The AI **MUST** perform changes in an **isolated git worktree**:

   * Created as `.worktrees/{workstream_id}/`.
   * Based on a known good branch (e.g., `main` / `develop`).
2. The AI **MUST**:

   * Confirm isolation using `git status` in the worktree.
   * Never directly edit the root worktree for these changes.

It is **FORBIDDEN** to perform broad code refactors directly in the main working tree.

### 2.3.2 Patch-First Change Representation

1. After changes in a worktree, the AI **MUST**:

   * Capture a unified diff patch via `git diff` or `git diff --cached`.
   * Store it under `.ledger/patches/{ws_id}-{run_id}.patch`.
2. Before applying patch in any other context, the AI **MUST**:

   * Validate patch scope vs. declared `file_scope`.
   * Check for oscillation via diff hashes.
3. Handoffs between tools (Aider → Codex → Claude, etc.) **MUST** use patches as the primary transport **when any multi-tool workflow is involved**.

It is **FORBIDDEN** to:

* Hand off “description-only” changes between tools without a patch artifact in multi-tool flows.
* Apply patch files directly to `main` without worktree validation and scope checks.

---

## 2.4 Execution Loop Pattern

For each workstream, the AI **MUST** follow this loop:

1. **Pre-Flight**

   * Run checks as defined in the Universal Phase Spec.
2. **Execute**

   * Run atomic workstream command:

     * Example:

       * `python scripts/run_workstream.py --ws-id ws-22-pipeline-plus-phase0-schema`
3. **Inspect**

   * Use `git status`, `Test-Path`, directory listings to see what actually changed.
4. **Self-Heal**

   * If expected artifacts are missing or incorrect, repair them directly.
5. **Test**

   * Run acceptance test commands (pytest, etc.).
6. **Repeat 3–5** as needed until all gates are green or circuit breakers trip.
7. **Emit Artifacts**

   * Capture patch + audit logs.

Skipping any step in this loop is **NOT PERMITTED**.

---

## 2.5 Interaction & Permission Rules

The AI:

* **MUST NOT** repeatedly ask:

  * “Would you like me to proceed with Phase X?”
  * “Should I run pytest now?”
* **MUST**:

  * Proceed automatically with all **obviously safe** next steps:

    * Running tests.
    * Creating missing directories/files per spec.
    * Activating venv / installing dependencies.

User interaction is reserved for:

* Ambiguous destructive operations (e.g., deleting data).
* Strategic decisions not encoded in the spec.

---

# 3. VALIDATION & ARCHITECTURE GUARDRAIL

*(The “Check”) – Ground Truth, Tests, and Structural Requirements*

This document defines:

* What counts as **Ground Truth**,
* The **testing obligations**, and
* The **minimum architecture layout** that must exist.

---

## 3.1 Ground Truth Definition

The following are the sole sources of truth:

1. **CLI Exit Codes and Outputs**

   * Exit code `0` + success pattern in stdout = success.
   * Any non-zero exit or presence of error patterns = failure.

2. **Filesystem State**

   * `Test-Path` (or equivalent) results.
   * Directory listings (`Get-ChildItem`, `ls`).
   * Actual presence and contents of files.

3. **Git and Database State**

   * Git:

     * `git status --short`
     * `git diff --name-only`
   * SQLite:

     * Contents of `runs`, `workstreams`, `errors`, `patches`, `events`.

Textual statements by the AI are **NOT** ground truth.

---

## 3.2 Test-First / Test-With Implementation

### 3.2.1 Test Obligation

For every phase that introduces or modifies executable logic:

1. Tests **MUST** exist **before** or be created **within the same phase**.
2. A phase **MUST NOT** be marked complete if:

   * There are no tests covering the new behavior, or
   * Existing relevant tests are skipped or commented out.

### 3.2.2 Acceptance Criteria Based on Tests

* A phase is **only complete** when all relevant tests pass, for example:

  * `"20 passed"` for `test_audit_logger.py`
  * `"24 passed"` for `test_task_queue.py`
* Partial passes with some failures are **NOT acceptable**.

The AI **MUST**:

1. Re-run tests until they pass or circuit breakers trip.
2. Treat “tests running in background” without output as **indeterminate**, not success.

---

## 3.3 Standard Directory & Schema Layout

The following structure is **mandatory** and **MUST** be created (typically by Phase 0) and preserved:

### 3.3.1 Queue & Task Flow

* `.tasks/inbox/`
* `.tasks/running/`
* `.tasks/done/`
* `.tasks/failed/`

Each directory **MUST** contain `.gitkeep` to enforce presence in Git.

### 3.3.2 Patch Ledger & Runs

* `.ledger/patches/`

  * Stores all patch files generated by AI tools.
* `.runs/`

  * Stores run/audit logs (e.g., `.runs/audit.jsonl`, per-run JSONL).

### 3.3.3 Schema & Config

* `schema/migrations/001_add_patches_table.sql`

  * Patches table with fields:

    * `run_id`, `ws_id`, `step_name`, `attempt`, `patch_file`, `diff_hash`, `line_count`, `files_modified`, `validated`, `applied`.
* `config/router.config.yaml`

  * Defines:

    * `apps` registry for tools.
    * `routing` rules per capability/constraint.

Any divergence from this layout is **FORBIDDEN** unless explicitly evolved via migration phases with their own tests and acceptance criteria.

---

## 3.4 State & Observability Guardrails

The SQLite database **MUST** maintain at least:

* `runs`
* `workstreams`
* `step_attempts`
* `errors`
* `events`
* `patches`

Each execution step **MUST**:

* Record its attempts in `step_attempts`.
* Log errors to `errors` with normalized signatures.
* Emit events to `events` for:

  * `state_transition`
  * `tool_started` / `tool_finished`
  * `patch_captured`
  * `patch_validated`
  * `circuit_breaker_trip`

The AI **MUST** treat missing state records as a **bug**, not as “optional”.

---

## 3.5 Completion Gate Logic (Canonical)

The system **MUST** implement a gate similar to:

```python
def can_mark_phase_done(phase_id: str, ws_id: str) -> bool:
    # 1. Dependencies satisfied
    if not all_dependencies_done(phase_id):
        return False

    # 2. Pre-flight recorded & successful
    if not preflight_passed(ws_id):
        return False

    # 3. Acceptance tests passed
    if not all_acceptance_tests_green(ws_id):
        return False

    # 4. Required directories/files exist
    if not required_artifacts_present(phase_id):
        return False

    # 5. Patches & audit artifacts exist
    if not patch_and_audit_artifacts_valid(ws_id):
        return False

    return True
```

Any attempt by an AI to declare a phase complete **without** passing this gate is a **protocol violation**.

---

# 4. ANTI-PATTERN BLOCKLIST

*(Strictly Forbidden Behaviors)*

This blocklist encodes **what must never happen**. If an AI exhibits any of these behaviors, it is **in violation of the Game Board Protocol**.

---

## 4.1 “Hallucination of Success”

**Forbidden Behavior:**

* Declaring:

  * “Complete ✅”
  * “Tested & Verified”
  * “All good”
* …without:

  * Running acceptance commands, and
  * Seeing concrete evidence (e.g., `N passed`, `Test-Path` checks).

Examples of violations:

* Tests triggered in background with no captured output, yet AI claims:

  * “pytest succeeded, everything is green.”
* Assuming that because a tool said “done”, the task is completed.

**Rule:**

> It is **FORBIDDEN** to claim success based solely on narrative reasoning or tool self-reports without CLI-level proof.

---

## 4.2 The “Planning Loop” Trap

**Forbidden Behavior:**

* Spending tens of thousands of tokens on:

  * Multi-page strategy documents,
  * Multi-phase execution plans,
  * Deep speculative analysis,
* …without executing a single atomic step (e.g., running Phase 0, creating a file + test).

Examples:

* Generating 9-phase refactor plans touching 65+ files, with **zero** `pytest` runs or worktree creation.
* Repeated `Plan()` tool calls producing long prose, but never invoking `run_workstream` or tests.

**Rule:**

> It is **FORBIDDEN** to remain in planning/documentation mode once Phase 0 can be executed.
> When in doubt, the AI **MUST** execute an atomic phase (e.g., “Phase 0 scaffold + one test”) over generating more plans.

---

## 4.3 Permission Bottlenecks

**Forbidden Behavior:**

* Asking the user for permission on **routine, safe operations**, such as:

  * Running tests,
  * Creating missing directories,
  * Activating venv,
  * Running `git status`.

Examples:

* “Would you like me to run pytest now?”
* “Should I create `.tasks/inbox`?”
* “Do you want me to proceed with Phase 1?”

**Rule:**

> It is **FORBIDDEN** to block progress on obvious next steps requiring no strategic choice.
> The AI **MUST** act like an operator and proceed automatically.

---

## 4.4 Context Pollution & Giant Refactors

**Forbidden Behavior:**

* Loading huge swaths of context (dozens of large files) without an immediate atomic action.
* Planning or executing:

  * Repo-wide refactors,
  * 20+ file path changes,
  * Massive section moves,
* …inside a single phase, without worktree + patch isolation and incremental tests.

Examples:

* “Refactor the entire core/ section and 20+ plugins in a single pass.”
* Designing 20+ workstreams and 9 phases in one planning call, with no Phase 0 execution.

**Rule:**

> It is **FORBIDDEN** to perform giant, fuzzy refactors.
> All changes **MUST** be broken down into small, patch-style phases with per-phase tests and isolation.

---

## 4.5 Trusting Tools Without Verification

**Forbidden Behavior:**

* Assuming Aider, Codex, or any CLI tool:

  * Created directories/files as requested, or
  * Ran tests successfully,
* …without verifying via CLI.

Examples:

* Noticing no new files in `git diff --name-only`, but still declaring the workstream done.
* Never checking `.worktrees/ws-*` contents after a workstream was “completed”.

**Rule:**

> It is **FORBIDDEN** to trust tools blindly.
> The AI **MUST** always verify artifacts and tests via CLI.

---

## 4.6 Declaring Completion Without Programmatic Acceptance

**Forbidden Behavior:**

* Marking a phase or workstream as complete after:

  * Copying files once,
  * Running no tests, or
  * Only visually inspecting code.

Examples:

* “I copied the spec and updated a script; this phase is complete.” (no `pytest`, no directory checks).
* “Everything compiles in my head.” (no actual execution).

**Rule:**

> It is **FORBIDDEN** to call any phase complete without:
>
> * All acceptance tests passing, and
> * All required files/dirs verified present.

---

## 4.7 Skipping Isolation (Direct Main-Branch Surgery)

**Forbidden Behavior:**

* Editing directly on the main worktree for multi-file or high-risk changes.
* Committing large, multi-module changes without an intermediate patch in `.ledger/patches/`.

Examples:

* Running Aider against `.` on `main` to refactor core modules and tests in one go.
* Applying patches directly to main without any worktree or validation.

**Rule:**

> It is **FORBIDDEN** to perform non-trivial edits outside isolated worktrees and patch workflows.

---

## 4.8 Multi-Phase Entanglement

**Forbidden Behavior:**

* Mixing responsibilities of multiple phases in a single workstream:

  * Implementing router, prompt engine, adapters, and docs all at once.
* Completing multiple conceptual phases without independent acceptance checks per phase.

Examples:

* Single phase that:

  * Writes multiple core scripts,
  * Adds 4+ documentation files,
  * Updates README, CLAUDE docs,
  * …and claims all are done simultaneously.

**Rule:**

> It is **FORBIDDEN** to bundle multiple independent responsibilities into one phase.
> Each phase **MUST** have one tight objective and its own acceptance tests.

---

## 4.9 Ignoring Circuit Breakers & Oscillation

**Forbidden Behavior:**

* Repeating the same failing operation and patch over and over:

  * Same diff applied; tests still fail.
* Never checking for oscillation (same failure signature + same diff hash).

**Rule:**

> It is **FORBIDDEN** to continue fix loops indefinitely without oscillation detection.
> Once circuit breaker criteria are met, the AI **MUST** stop and mark the workstream as failed/blocked.

---

## 4.10 Summary: Zero-Tolerance Anti-Patterns

An AI operating under this protocol:

* **MUST** prefer **small, verified steps** over big, speculative refactors.
* **MUST** treat **tests and CLI output** as the only basis for success.
* **MUST** use **worktrees + patches** for non-trivial changes.
* **MUST NOT**:

  * Hallucinate success,
  * Live in planning loops,
  * Ask for permission to do its basic job,
  * Or skip isolation and validation.

If any of these anti-patterns appear, the AI’s run is considered **non-compliant** and **MUST** be halted or quarantined until corrected.
