# .ai-module-manifest
# AI-readable module specification for engine

module: "engine"
purpose: "Job execution engine: task queue, worker pool, sandbox management"
layer: "domain"  # Domain layer - execution coordination

# Note
note: "This is distinct from core.engine - this is the job-level execution engine for multi-worker scenarios"

# Entry points
entry_points:
  - file: "job_engine.py"
    class: "JobEngine"
    function: "execute_job(job_spec)"
    description: "Execute multi-task job with worker pool"
    
  - file: "worker_pool.py"
    class: "WorkerPool"
    description: "Manage pool of CLI workers"
    
  - file: "sandbox.py"
    class: "Sandbox"
    description: "Isolated execution environment per worker"

# Key patterns
key_patterns:
  - "Job = collection of tasks across workstreams"
  - "Workers = CLI instances (Aider, Copilot, etc.)"
  - "Sandboxes = isolated worktrees/directories"
  - "Task queue with priority and dependencies"
  - "Worker lifecycle: spawn → assign → execute → merge"

# Architecture
architecture:
  job_engine:
    responsibility: "Coordinate job execution"
    components: ["task_queue", "worker_pool", "result_aggregator"]
    
  worker_pool:
    responsibility: "Manage worker lifecycle"
    operations: ["spawn", "assign_task", "monitor", "teardown"]
    
  sandbox:
    responsibility: "Isolated execution environment"
    features: ["git worktree", "file scope isolation", "cleanup"]

# Common tasks
common_tasks:
  - task: "Execute job"
    code: |
      from engine.job_engine import JobEngine
      engine = JobEngine(max_workers=3)
      result = engine.execute_job(job_spec)
      
  - task: "Create worker pool"
    code: |
      from engine.worker_pool import WorkerPool
      pool = WorkerPool(size=3, tool="aider")
      
  - task: "Create sandbox"
    code: |
      from engine.sandbox import Sandbox
      sandbox = Sandbox(base_dir=".worktrees/worker-001")

# Gotchas
gotchas:
  - "Workers are CLI processes (not threads)"
  - "Sandboxes use git worktrees or separate directories"
  - "Task assignment considers file scope conflicts"
  - "Worker cleanup critical (kill processes, rm worktrees)"
  - "Parallel execution requires careful dependency management"

# Dependencies
dependencies:
  external:
    - subprocess
    - multiprocessing
  internal:
    - core.engine (for single-worker execution)
    - aim.bridge (for tool discovery)

# Status
status:
  maturity: "alpha"  # In development
  test_coverage: "~40%"
  production_ready: false
  note: "Part of parallelism work (Phase 4+)"

# AI quick reference
ai_quick_reference:
  execute_job: "from engine.job_engine import JobEngine; JobEngine().execute_job(spec)"
  worker_pool: "from engine.worker_pool import WorkerPool; WorkerPool(size=3)"
