[
  {
    "op": "add",
    "path": "/meta/patch_metadata/008",
    "value": {
      "patch_id": "008-resilience-patterns",
      "patch_ulid": "01JDK0019AB09DAC1CDC9763AA",
      "created_at": "2025-11-23T12:15:26.788Z",
      "description": "Document resilience patterns (Circuit Breaker, Retry Strategies, Resilient Executor) for fault-tolerant execution",
      "source_files": [
        "tests/resilience/test_circuit_breaker.py",
        "tests/resilience/test_retry.py",
        "tests/resilience/test_resilient_executor.py"
      ],
      "operations_count": 2,
      "priority": "HIGH",
      "approved_by": "human",
      "applied": false
    }
  },
  {
    "op": "add",
    "path": "/meta/resilience_patterns",
    "value": {
      "description": "Fault-tolerance patterns for reliable execution of workstreams and tool operations",
      "purpose": "Prevent cascading failures, handle transient errors, protect external dependencies",
      "location": "core/engine/resilience.py",
      "workstream": "WS-03-03A",
      "patterns": {
        "circuit_breaker": {
          "description": "Prevents cascading failures by blocking calls to failing services",
          "class": "CircuitBreaker",
          "states": {
            "CLOSED": {
              "description": "Normal operation - calls pass through",
              "behavior": "Track failures, transition to OPEN if threshold exceeded",
              "next_states": ["OPEN"]
            },
            "OPEN": {
              "description": "Failure threshold exceeded - calls blocked",
              "behavior": "Reject all calls immediately, wait for recovery_timeout",
              "next_states": ["HALF_OPEN"],
              "exception": "CircuitBreakerOpen"
            },
            "HALF_OPEN": {
              "description": "Testing recovery - allow trial call",
              "behavior": "Single call attempted, success → CLOSED, failure → OPEN",
              "next_states": ["CLOSED", "OPEN"]
            }
          },
          "state_machine": {
            "initial_state": "CLOSED",
            "terminal_states": [],
            "transitions": {
              "CLOSED → OPEN": "failure_count >= failure_threshold",
              "OPEN → HALF_OPEN": "time_since_open >= recovery_timeout",
              "HALF_OPEN → CLOSED": "trial call succeeds",
              "HALF_OPEN → OPEN": "trial call fails"
            }
          },
          "configuration": {
            "failure_threshold": {
              "type": "int",
              "default": 5,
              "description": "Number of consecutive failures before opening circuit"
            },
            "recovery_timeout": {
              "type": "int",
              "default": 60,
              "description": "Seconds to wait before attempting recovery (OPEN → HALF_OPEN)",
              "unit": "seconds"
            },
            "name": {
              "type": "str",
              "default": "unnamed",
              "description": "Circuit breaker identifier for logging/monitoring"
            }
          },
          "methods": {
            "call": {
              "signature": "call(func: Callable, *args, **kwargs) -> Any",
              "description": "Execute function with circuit breaker protection",
              "raises": ["CircuitBreakerOpen", "original exceptions"],
              "behavior": [
                "If OPEN: raise CircuitBreakerOpen immediately",
                "If CLOSED: execute func, track success/failure",
                "If HALF_OPEN: execute func, transition based on result"
              ]
            },
            "reset": {
              "signature": "reset() -> None",
              "description": "Manually reset circuit to CLOSED state",
              "use_case": "After fixing underlying issue"
            },
            "get_state": {
              "signature": "get_state() -> Dict",
              "description": "Get current circuit state and metrics",
              "returns": {
                "name": "Circuit breaker name",
                "state": "Current state (closed/open/half_open)",
                "failure_count": "Consecutive failures",
                "success_count": "Total successes",
                "failure_threshold": "Threshold for opening",
                "opened_at": "Timestamp when opened (if OPEN)"
              }
            }
          },
          "metrics_tracked": {
            "failure_count": "Consecutive failures (reset on success)",
            "success_count": "Total successful calls",
            "opened_at": "Timestamp when circuit opened",
            "last_failure_time": "Timestamp of most recent failure"
          },
          "test_coverage": {
            "test_file": "tests/resilience/test_circuit_breaker.py",
            "test_count": 10,
            "tests": [
              "test_create_circuit_breaker - Initialization with config",
              "test_successful_calls - Successful calls pass through",
              "test_failed_calls_increment_counter - Failure tracking",
              "test_circuit_opens_after_threshold - CLOSED → OPEN transition",
              "test_open_circuit_blocks_calls - CircuitBreakerOpen exception",
              "test_circuit_transitions_to_half_open - OPEN → HALF_OPEN via timeout",
              "test_half_open_failure_reopens_circuit - HALF_OPEN → OPEN on failure",
              "test_manual_reset - Manual reset to CLOSED",
              "test_get_state - State and metrics retrieval"
            ]
          }
        },
        "retry_strategies": {
          "description": "Configurable retry logic for transient failures",
          "base_class": "RetryStrategy",
          "implementations": {
            "simple_retry": {
              "class": "SimpleRetry",
              "description": "Fixed delay between retries",
              "configuration": {
                "max_attempts": {
                  "type": "int",
                  "default": 3,
                  "description": "Maximum retry attempts"
                },
                "delay": {
                  "type": "float",
                  "default": 1.0,
                  "description": "Constant delay between retries (seconds)"
                }
              },
              "delay_pattern": "Constant - same delay for every retry",
              "formula": "delay = fixed_delay",
              "example": "3 attempts with 1.0s delay → delays: [1.0, 1.0, 1.0]",
              "use_case": "Simple transient errors, predictable timing"
            },
            "exponential_backoff": {
              "class": "ExponentialBackoff",
              "description": "Exponentially increasing delay with optional jitter",
              "configuration": {
                "max_attempts": {
                  "type": "int",
                  "default": 5,
                  "description": "Maximum retry attempts"
                },
                "base_delay": {
                  "type": "float",
                  "default": 1.0,
                  "description": "Base delay for exponential calculation (seconds)"
                },
                "max_delay": {
                  "type": "float",
                  "default": 60.0,
                  "description": "Maximum delay cap (seconds)"
                },
                "exponential_base": {
                  "type": "float",
                  "default": 2.0,
                  "description": "Base for exponential growth (typically 2.0)"
                },
                "jitter": {
                  "type": "bool",
                  "default": true,
                  "description": "Add randomness to prevent thundering herd"
                }
              },
              "delay_pattern": "Exponential - delay doubles each retry",
              "formula": "delay = min(base_delay * exponential_base^attempt, max_delay)",
              "jitter_formula": "delay * random(0.5, 1.5) if jitter enabled",
              "example": "base=1.0, exp=2.0 → delays: [2.0, 4.0, 8.0, 16.0, 32.0]",
              "example_with_cap": "base=1.0, exp=2.0, max=10.0 → delays: [2.0, 4.0, 8.0, 10.0, 10.0]",
              "use_case": "Rate limiting, API throttling, load-based failures"
            }
          },
          "methods": {
            "execute": {
              "signature": "execute(func: Callable, *args, **kwargs) -> Any",
              "description": "Execute function with retry logic",
              "raises": ["RetryExhausted"],
              "behavior": [
                "Attempt 1: Execute func immediately",
                "On failure: Wait for get_delay(attempt), retry",
                "Repeat until success or max_attempts reached",
                "If all attempts fail: raise RetryExhausted"
              ]
            },
            "get_delay": {
              "signature": "get_delay(attempt: int) -> float",
              "description": "Calculate delay for given attempt number",
              "returns": "Delay in seconds (float)"
            }
          },
          "exception": {
            "class": "RetryExhausted",
            "description": "Raised when all retry attempts are exhausted",
            "fields": {
              "attempts": "Total attempts made",
              "last_exception": "The final exception that caused failure"
            },
            "usage": "Signals that transient error persisted beyond retry threshold"
          },
          "test_coverage": {
            "test_file": "tests/resilience/test_retry.py",
            "test_count": 11,
            "tests_simple_retry": [
              "test_create_simple_retry - Initialization",
              "test_get_delay_is_constant - Constant delay verification",
              "test_successful_execution - Success on first try",
              "test_retry_after_failure - Retry with delay",
              "test_exhaust_retries - RetryExhausted exception"
            ],
            "tests_exponential_backoff": [
              "test_create_exponential_backoff - Initialization",
              "test_exponential_delay_growth - Exponential formula (2, 4, 8, 16)",
              "test_max_delay_cap - Delay capping at max_delay",
              "test_jitter_adds_randomness - Jitter variation",
              "test_successful_after_retries - Success after retries"
            ],
            "tests_exception": [
              "test_exception_has_metadata - RetryExhausted contains attempts and last_exception"
            ]
          }
        },
        "resilient_executor": {
          "description": "Combines circuit breaker + retry for robust tool execution",
          "class": "ResilientExecutor",
          "purpose": "Per-tool resilience with independent circuits and retry strategies",
          "architecture": {
            "pattern": "Decorator/Wrapper",
            "combines": ["CircuitBreaker", "RetryStrategy"],
            "isolation": "Each tool has independent circuit breaker and retry strategy"
          },
          "methods": {
            "register_tool": {
              "signature": "register_tool(tool_id: str, failure_threshold: int = 5, recovery_timeout: int = 60, max_retries: int = 3, retry_strategy: str = 'simple') -> None",
              "description": "Register a tool with resilience configuration",
              "parameters": {
                "tool_id": "Unique tool identifier",
                "failure_threshold": "Circuit breaker threshold",
                "recovery_timeout": "Circuit recovery timeout (seconds)",
                "max_retries": "Max retry attempts",
                "retry_strategy": "'simple' or 'exponential'"
              }
            },
            "execute": {
              "signature": "execute(tool_id: str, func: Callable, *args, **kwargs) -> Any",
              "description": "Execute function with resilience protection",
              "behavior": [
                "Auto-register tool if not registered",
                "Wrap func with retry strategy",
                "Wrap retry with circuit breaker",
                "Return result or raise exception"
              ],
              "flow": "func → retry wrapper → circuit breaker → result",
              "raises": ["CircuitBreakerOpen", "RetryExhausted"]
            },
            "get_tool_state": {
              "signature": "get_tool_state(tool_id: str) -> Optional[Dict]",
              "description": "Get circuit breaker state for tool",
              "returns": "State dict or None if tool not registered"
            },
            "get_all_states": {
              "signature": "get_all_states() -> Dict[str, Dict]",
              "description": "Get all tool circuit states",
              "returns": "Map of tool_id to state dict"
            },
            "reset_tool": {
              "signature": "reset_tool(tool_id: str) -> None",
              "description": "Manually reset tool's circuit breaker"
            }
          },
          "usage_example": {
            "setup": [
              "executor = ResilientExecutor()",
              "executor.register_tool('aider', failure_threshold=3, max_retries=5)"
            ],
            "execute": [
              "result = executor.execute('aider', lambda: aider_api.edit(file))"
            ],
            "monitor": [
              "state = executor.get_tool_state('aider')",
              "if state['state'] == 'open':",
              "    log.warning('Aider circuit is open, service may be down')"
            ]
          },
          "isolation_benefits": {
            "independent_circuits": "Failure in tool A doesn't affect tool B",
            "per_tool_thresholds": "Configure failure_threshold per tool based on reliability",
            "selective_blocking": "Circuit opens only for failing tool, others continue",
            "targeted_recovery": "Reset individual circuits without affecting others"
          },
          "test_coverage": {
            "test_file": "tests/resilience/test_resilient_executor.py",
            "test_count": 11,
            "tests": [
              "test_create_executor - Initialization",
              "test_register_tool - Tool registration",
              "test_execute_successful_call - Success execution",
              "test_auto_register_on_execute - Auto-registration on first use",
              "test_retry_on_failure - Retry logic integration",
              "test_circuit_opens_after_threshold - Circuit opening",
              "test_circuit_blocks_when_open - CircuitBreakerOpen blocking",
              "test_get_tool_state - State retrieval",
              "test_get_nonexistent_tool_state - None for missing tool",
              "test_reset_tool - Manual circuit reset",
              "test_get_all_states - All tools state retrieval",
              "test_separate_circuits_per_tool - Circuit isolation verification"
            ]
          }
        }
      },
      "integration": {
        "with_tool_adapters": {
          "description": "Wrap adapter.execute() with ResilientExecutor",
          "pattern": [
            "executor = ResilientExecutor()",
            "executor.register_tool(tool_id, ...)",
            "result = executor.execute(tool_id, lambda: adapter.execute(request))"
          ],
          "benefit": "Tool adapters get circuit breaker + retry automatically"
        },
        "with_workstream_execution": {
          "description": "Orchestrator uses resilient executor for step execution",
          "pattern": [
            "For each step in workstream:",
            "  tool_id = step.tool_id",
            "  result = resilient_executor.execute(tool_id, lambda: execute_step(step))",
            "  Handle CircuitBreakerOpen → mark step as blocked",
            "  Handle RetryExhausted → mark step as failed"
          ],
          "benefit": "Workstreams resilient to transient failures and cascading errors"
        }
      },
      "design_benefits": {
        "prevent_cascading_failures": "Circuit breaker isolates failing dependencies",
        "handle_transient_errors": "Retry strategies recover from temporary issues",
        "protect_external_services": "Rate limiting via exponential backoff",
        "per_tool_configuration": "Tailor resilience to each tool's reliability profile",
        "observable": "Get states for monitoring and debugging",
        "testable": "Patterns tested with 32 unit tests"
      },
      "best_practices": {
        "circuit_breaker_thresholds": {
          "low_reliability_tools": "failure_threshold=2-3 (aider, external APIs)",
          "high_reliability_tools": "failure_threshold=5-10 (git, pytest)",
          "critical_operations": "failure_threshold=1 (deployment, data migration)"
        },
        "retry_strategies": {
          "transient_errors": "SimpleRetry with 3 attempts, 1s delay",
          "rate_limiting": "ExponentialBackoff with jitter to avoid thundering herd",
          "network_issues": "ExponentialBackoff with max_delay=60s"
        },
        "recovery_timeouts": {
          "fast_recovery": "recovery_timeout=30s (local tools)",
          "moderate_recovery": "recovery_timeout=60s (external APIs)",
          "slow_recovery": "recovery_timeout=300s (databases, critical services)"
        },
        "monitoring": {
          "log_circuit_opens": "Alert when circuit opens (service degradation)",
          "track_retry_counts": "Monitor retry_exhausted frequency",
          "dashboard_tool_states": "Real-time view of all circuit states"
        }
      }
    }
  }
]
