Here’s a spec-style document you can drop into the repo and point AI tools at to implement the behavior you described.

---

````markdown
---
status: draft
doc_type: spec
doc_id: DOC-SPEC-HEADLESS-CLI-SUPERVISION-001
module_refs:
  - tui_app/core/sqlite_state_backend.py
  - tui_app/core/state_client.py
  - tui_app/core/pattern_client.py
  - tui_app/panels/tool_health_panel.py
  - tui_app/panels/log_stream_panel.py
  - tui_app/panels/file_lifecycle_panel.py
  - tui_app/panels/dashboard_panel.py
  - tui_app/main.py
  - tui_app/config/tui_config.yaml
---

# Headless CLI Supervision & Approval Spec (TUI + Orchestrator Integration)

## 0. Purpose & Scope

This document defines the changes an AI assistant must make to:

1. Detect when **headless CLI tools** (e.g., aider, codex, open_spec, etc.) have **failed, stalled, or hung**.
2. Handle **“waiting for user approval”** in a world where **no terminal is visible**.
3. Surface these states clearly in the existing **TUI panels** (Dashboard, Tool Health, Log Stream, File Lifecycle, Pattern Activity).

The implementation must integrate cleanly with:

- The existing **SQLite state backend** (`.worktrees/pipeline_state.db`) and `StateClient`/`SQLiteStateBackend`.
- The existing **TUI app** (`tui_app/main.py`) and panel architecture (panel registry, layout manager, panel context).
- The existing **Tool Health** and **Log Stream** panels that read `logs/combined.log`.

---

## 1. Architecture Snapshot (Current State)

### 1.1 TUI & Panels

- TUI is Textual-based, with panels registered via `@register_panel` and mounted by `PipelineTUI` using `PanelContext` (state_client, pattern_client, config).
- Current panels:
  - `dashboard` – pipeline summary via `StateClient.get_pipeline_summary()` and `get_tasks()`.
  - `file_lifecycle` – patch ledger & executions via `StateClient.get_patch_ledger()` and `get_executions()`.
  - `tool_health` – parses `logs/combined.log` to derive tool status (“ok/warn/error/info”) from recent JSON log lines.
  - `log_stream` – tails `logs/combined.log`.
  - `pattern_activity` – reads pattern executions from SQLite via `PatternClient`.

### 1.2 State & Database

- `StateClient` reads pipeline state via an abstract `StateBackend` (`get_pipeline_summary`, `get_tasks`, `get_task`, `get_executions`, `get_patch_ledger`). :contentReference[oaicite:10]{index=10}
- `SQLiteStateBackend` stores state in `.worktrees/pipeline_state.db` with tables:
  - `uet_executions`
  - `uet_tasks`
  - `patch_ledger`

### 1.3 Logging

- Tool and pipeline logs go to `logs/combined.log` (path & max_lines from `tui_app/config/tui_config.yaml` via `TUIConfig.logs`).
- `ToolHealthWidget` already reads the last ~400 JSON lines and infers status based on `msg` text. :contentReference[oaicite:13]{index=13}

---

## 2. High-Level Behavior Requirements

Think of the system in terms of **two separate but connected problems**:

1. **Detecting when a headless CLI has gone bad**
   - Detect **failed / stalled / hung** tool runs.
   - Record this state in **SQLite** and **logs**.
   - Reflect this in **Tool Health + Dashboard** UI.

2. **Handling “I need your approval” without a visible terminal**
   - In **headless mode** (`HEADLESS=1` or `CI=1`):
     - Tools must **never** block on stdin.
     - Instead they emit a **structured approval request** and either:
       - Exit with a special code (e.g. 90), or
       - Wait by polling the DB (with a max wait timeout).
   - The TUI must show **pending approvals**, and allow the user to approve/reject.

---

## 3. New Data Model Extensions (SQLite)

### 3.1 Table: `tool_runs`

Create a new table in `.worktrees/pipeline_state.db` for **CLI tool executions**.

**Required schema** (extend `SQLiteStateBackend._initialize_schema`): :contentReference[oaicite:14]{index=14}

```sql
CREATE TABLE IF NOT EXISTS tool_runs (
    tool_run_id      TEXT PRIMARY KEY,
    tool_name        TEXT NOT NULL,
    execution_id     TEXT,          -- optional link to uet_executions.execution_id
    status           TEXT NOT NULL, -- queued/running/completed/failed/stalled/waiting_approval
    exit_code        INTEGER,
    started_at       TIMESTAMP,
    completed_at     TIMESTAMP,
    last_output_at   TIMESTAMP,
    last_heartbeat_at TIMESTAMP,
    last_error_msg   TEXT,
    metadata         JSON
);
````

**Status values (MUST):**

* `queued`
* `running`
* `completed`
* `failed`
* `stalled`
* `waiting_approval`

### 3.2 Table: `approvals`

Create an `approvals` table for **approval requests** generated by tools:

```sql
CREATE TABLE IF NOT EXISTS approvals (
    approval_id   TEXT PRIMARY KEY,
    tool_run_id   TEXT NOT NULL,          -- FK into tool_runs.tool_run_id
    tool_name     TEXT NOT NULL,
    execution_id  TEXT,
    question      TEXT NOT NULL,
    options_json  TEXT NOT NULL,          -- JSON array of {value, label}
    status        TEXT NOT NULL,          -- pending/approved/rejected/expired
    chosen_value  TEXT,
    created_at    TIMESTAMP NOT NULL,
    decided_at    TIMESTAMP,
    FOREIGN KEY (tool_run_id) REFERENCES tool_runs(tool_run_id)
);
```

**Approval status values (MUST):**

* `pending`
* `approved`
* `rejected`
* `expired` (for timeouts / abandonment)

### 3.3 StateBackend Extensions

Extend `StateBackend` and `StateClient` with new read APIs (no write APIs, orchestrator writes directly).

Add new dataclasses:

```python
# tui_app/core/state_client.py

@dataclass
class ToolRunInfo:
    tool_run_id: str
    tool_name: str
    execution_id: Optional[str]
    status: str
    exit_code: Optional[int]
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    last_output_at: Optional[datetime]
    last_heartbeat_at: Optional[datetime]
    last_error_msg: Optional[str]
    metadata: Dict[str, Any]


@dataclass
class ApprovalInfo:
    approval_id: str
    tool_run_id: str
    tool_name: str
    execution_id: Optional[str]
    question: str
    options: List[Dict[str, str]]  # [{"value": "...", "label": "..."}]
    status: str                    # pending/approved/rejected/expired
    chosen_value: Optional[str]
    created_at: Optional[datetime]
    decided_at: Optional[datetime]
```

Add abstract methods to `StateBackend`:

```python
class StateBackend(ABC):
    ...
    @abstractmethod
    def get_tool_runs(self, limit: int = 100) -> List[ToolRunInfo]:
        ...

    @abstractmethod
    def get_approvals(self, status_filter: Optional[str] = None, limit: int = 50) -> List[ApprovalInfo]:
        ...
```

Implement these in `InMemoryStateBackend` (for smoke tests) and `SQLiteStateBackend` by querying `tool_runs` and `approvals`.

Expose thin wrappers on `StateClient`:

```python
class StateClient:
    ...
    def get_tool_runs(self, limit: int = 100) -> List[ToolRunInfo]:
        return self._backend.get_tool_runs(limit)

    def get_approvals(self, status_filter: Optional[str] = None, limit: int = 50) -> List[ApprovalInfo]:
        return self._backend.get_approvals(status_filter, limit)
```

---

## 4. CLI Supervisor: `run_cli_tool(...)`

Create a new module for the orchestrator, e.g.:

* `orchestrator/cli_supervisor.py`

### 4.1 Function Contract

Implement:

```python
def run_cli_tool(
    tool_name: str,
    args: list[str],
    execution_id: str | None,
    timeout_seconds: int,
    no_output_timeout_seconds: int,
    env: dict | None = None,
) -> int:
    """
    Launch a CLI tool as a supervised job.

    Responsibilities:
      - Create tool_run row in tool_runs
      - Spawn subprocess and stream stdout/stderr
      - Write structured JSON logs to logs/combined.log
      - Enforce:
          * hard wall-clock timeout
          * no-output timeout
      - Update tool_runs.status on:
          * completed / failed / stalled / waiting_approval
      - Return exit code
    """
```

### 4.2 Supervision Rules

**The supervisor MUST:**

1. **Insert initial tool_run record** with `status="running"` and timestamps.

2. **Capture stdout + stderr**:

   * Stream to console/log capture if needed.
   * Append JSON lines to `logs/combined.log`:

     ```json
     {
       "event": "tool_output",
       "tool": "aider",
       "toolRunId": "TR-123",
       "executionId": "EX-123",
       "timestamp": "...",
       "stream": "stdout",
       "text": "..."
     }
     ```

3. **Track heartbeats**:

   * Whenever a line parses as JSON and includes `"event": "heartbeat"`, update `last_heartbeat_at`.
   * If no heartbeat or output for `no_output_timeout_seconds`, set `status="stalled"`, log an event, and kill the process.

4. **Apply hard timeout**:

   * If wall-clock runtime exceeds `timeout_seconds`, mark `status="failed"` with reason `"timeout"`, kill the process, and log.

5. **On process exit**:

   * If exit code == 0 and no failure markers → `status="completed"`.
   * If exit code != 0 and not special approval code → `status="failed"`.
   * If exit code == 90 (special approval-needed code; see §5) → `status="waiting_approval"`.

6. **Emit status-change events to logs**:

   ```json
   {
     "event": "tool_status_change",
     "tool": "aider",
     "toolRunId": "TR-123",
     "executionId": "EX-123",
     "status": "failed",
     "reason": "exit_code != 0",
     "exit_code": 1,
     "timestamp": "..."
   }
   ```

These log events will be consumed by `ToolHealthWidget` and `LogStreamWidget`.

---

## 5. Headless Mode Approval Protocol

### 5.1 Headless Environment Rule

Define a **hard rule** used across all custom tools:

> If `HEADLESS=1` or `CI=1` is set in the environment, CLI tools **MUST NOT** block on interactive stdin.

Instead, when they need user input, they MUST:

1. Emit an `approval_needed` JSON event.
2. Insert a row into `approvals`.
3. Exit with a special code (90), **or** poll `approvals` until not `pending` (with timeout).

### 5.2 Approval Needed Event Format

When a tool reaches a decision point in headless mode:

```json
{
  "event": "approval_needed",
  "tool": "open_spec_cli",
  "toolRunId": "TR-456",
  "executionId": "EX-456",
  "approvalId": "AP-00123",
  "question": "Apply these 17 file changes to repo main?",
  "options": [
    {"value": "approve", "label": "Approve and apply changes"},
    {"value": "reject", "label": "Reject and discard changes"}
  ],
  "default": "reject",
  "timestamp": "..."
}
```

The tool then **either**:

* Writes this JSON to stdout/stderr so the supervisor can parse it, and exits with code `90`, **or**
* Writes it and then polls `approvals` until status changes or a max wait timeout is hit (after which it treats it as `expired` / `rejected`).

### 5.3 Writing to `approvals`

The supervisor (or a small helper) MUST:

1. Parse `approval_needed` events from tool output.
2. Insert a row into `approvals` with:

   * `status = "pending"`
   * `options_json` = JSON-serialized `options` list.
   * `created_at = now()`
3. Update the related `tool_runs.status` to `"waiting_approval"`.

### 5.4 Recording the Decision

A background worker OR user action in the UI MUST:

1. Update `approvals.status` to one of:

   * `approved`
   * `rejected`
   * `expired`
2. Set `chosen_value` to the selected option’s `value`.
3. Set `decided_at = now()`.

If you choose the **re-run** pattern:

* The orchestrator, upon seeing a non-pending decision, re-runs the tool with a flag/env like `--auto-approval-id AP-00123`, and the tool consumes the recorded choice.

If you choose the **long-running worker** pattern:

* The tool remains running and polls `approvals` until `status != "pending"`.

The spec does not force one or the other; pick one and implement consistently.

---

## 6. TUI Changes (User Awareness)

### 6.1 Tool Health Panel

Update `ToolHealthWidget` to consume structured events and new DB state.

**Current behavior (for reference):**

* Reads last ~400 lines from `logs/combined.log`.
* Parses each line as JSON, uses `data["toolName"]` and `data["msg"]`.
* Derives a simple status (`ok/warn/error/info`) via `_derive_status(message)` which checks message strings like `"error"`, `"failed"`, `"registered successfully"`.

**New behavior (required):**

1. **Understand structured events**:

   * For `event = "tool_status_change"`:

     * Use `data["status"]` directly if present (`running/completed/failed/stalled/waiting_approval`).
   * For `event = "approval_needed"`:

     * Treat as `status = "waiting_approval"` for that `toolRunId`.

2. **Derive a richer status enum**:

   Replace `_derive_status(message: str) -> str` with something like:

   ```python
   def _derive_status(self, data: dict) -> str:
       status = (data.get("status") or "").lower()
       if status in {"running", "completed", "failed", "stalled", "waiting_approval"}:
           return status

       # Fallback to message-based heuristics for legacy lines
       msg = (data.get("msg") or "").lower()
       ...
   ```

3. **Display mapping in the table**:

   * Map statuses to styles:

     * `running` → cyan
     * `completed` → green
     * `failed` → red
     * `stalled` → magenta or red
     * `waiting_approval` → yellow

   * Update the summary card to show counts:

     * `Running`, `Completed`, `Failed`, `Stalled`, `Waiting Approval`.

4. **Optional DB-backed view**:

   * Supplement log-derived status with `state_client.get_tool_runs(limit=...)` and merge by tool name or `tool_run_id`.

### 6.2 Dashboard Panel

Update `DashboardWidget` to surface **global alerts** from tool_runs / approvals.

Requirements:

1. Use `state_client.get_tool_runs()` to compute:

   * `stalled_count = number of tool_runs with status="stalled"`
   * `waiting_approval_count = number of tool_runs with status="waiting_approval"`

2. Add an “Alerts” section to the rendered content:

   Example:

   ```text
   [bold cyan]Alerts:[/]
   [red]Stalled tools:[/] 2
   [yellow]Waiting approvals:[/] 1
   ```

3. This section MUST appear near the top so the user always sees if something is stuck.

### 6.3 Approvals View (Minimal)

For now, implement a **minimal inline approvals list** on an existing panel (no need for a full new panel yet):

* **Option A (recommended)**: extend `ToolHealthWidget` with a second table listing **pending approvals** from `state_client.get_approvals(status_filter="pending")`.
* **Option B**: extend `DashboardWidget` with a simple list of pending approvals (tool name + truncated question).

Structure for each approval:

```text
● [tool_name] – "question text..." (status: pending)
```

This is **read-only** from the TUI’s perspective for now; decisions can be made via:

* Future interactive controls, or
* An external script / CLI that updates the `approvals` table.

### 6.4 Log Stream Panel

No structural changes required; but the new JSON events (`tool_status_change`, `approval_needed`) should naturally appear there because they are written to `logs/combined.log`.

---

## 7. Implementation Steps for AI

### 7.1 Database & State Layer

1. Update `SQLiteStateBackend._initialize_schema` to create `tool_runs` and `approvals` tables if they don’t exist.
2. Extend `StateBackend` interface with `get_tool_runs` and `get_approvals`.
3. Implement these methods in:

   * `InMemoryStateBackend` (seed with a couple of fake runs and approvals for testing).
   * `SQLiteStateBackend` (SQL queries, mapping to new dataclasses).
4. Expose wrapper methods on `StateClient`.

### 7.2 CLI Supervisor Module

1. Create `orchestrator/cli_supervisor.py` (or equivalent existing orchestrator module).
2. Implement `run_cli_tool(...)` per §4.
3. Update all orchestrator call sites to use `run_cli_tool` instead of spawning tools directly.

### 7.3 Headless Approval Protocol

1. Ensure orchestrator sets `HEADLESS=1` (and/or `CI=1`) for headless runs.
2. Implement `approval_needed` event emission in each controllable tool, OR wrap their behavior.
3. Implement a helper to:

   * Parse `approval_needed` events.
   * Insert `approvals` rows.
   * Update `tool_runs.status="waiting_approval"`.

### 7.4 TUI Updates

1. Extend `ToolHealthWidget` to:

   * Parse structured JSON events (`tool_status_change`, `approval_needed`).
   * Use state_client tool run data to display richer status.

2. Extend `DashboardWidget` to call new state_client methods and show alerts.

3. Add a small approvals list area (either in Dashboard or Tool Health).

4. Verify TUI still launches via:

   ```bash
   python -m gui.tui_app.main --use-mock-data --smoke-test
   ```

5. Update / add tests to cover:

   * `StateBackend` new methods (SQLite + InMemory).
   * Tool Health panel parsing of structured events and stalled/waiting_approval statuses.
   * Dashboard alerts rendering.

---

## 8. Edge Cases & Additional Considerations

AI should also account for:

1. **Non-cooperative third-party tools**:

   * If a tool ignores HEADLESS and blocks on stdin, mark it as **unsafe for headless use** and enforce a hard timeout with appropriate log event.

2. **Zombie processes**:

   * If `tool_runs.status` is `running` but process is gone, supervisor should reconcile on startup and mark as `failed` or `stalled`.

3. **Approval expiry**:

   * Implement a simple rule: approvals older than N hours auto-mark as `expired` and treat “expired” like “rejected”.

4. **Concurrency**:

   * It is valid to have multiple tool runs of the same tool; use `tool_run_id` as the unique key, not just `tool_name`.

---

## 9. Success Criteria (for AI / Tests)

The change is considered successfully implemented when:

1. Every CLI tool launched by the orchestrator goes through `run_cli_tool(...)` and creates a `tool_runs` row.
2. If a tool:

   * Exits non-zero → Tool Health shows it as **FAILED** and Dashboard shows at least one failure.
   * Produces no output/heartbeat for > configured thresholds → Tool Health shows **STALLED**, Dashboard shows stalled count.
   * Emits `approval_needed` in headless mode → `approvals` row created; Tool Health / Dashboard show **waiting approval**.
3. `logs/combined.log` clearly shows JSON `tool_status_change` and `approval_needed` events, visible in Log Stream panel.
4. TUI launches successfully and displays:

   * Tool counts (OK / running / stalled / failed / waiting_approval).
   * At least a minimal list of pending approvals.

```

---

```


Here’s a spec you can drop into `project_knowledge/` as something like:

`HEADLESS_CLI_EXECUTION_SPEC_V1.md`

You can tweak the `doc_id` to fit your registry.

---

````markdown
---
doc_id: DOC-SPEC-HEADLESS-CLI-EXECUTION-001
status: draft
role: spec
spec_version: 1
intended_consumer: agentic_ai
targets:
  - orchestrator/*
  - core/state/*
  - tui_app/core/*
  - tui_app/panels/dashboard_panel.py
  - tui_app/panels/tool_health_panel.py
  - tui_app/panels/log_stream_panel.py
  - tui_app/panels/pattern_activity_panel.py
single_source_of_truth_for:
  - headless_cli_supervision
  - cli_status_model
  - approval_protocol
---

# HEADLESS_CLI_EXECUTION_SPEC_V1

## 0. Purpose

This spec defines how **all CLI tools** are launched, monitored, and surfaced in the UI when running in **headless mode**.

It covers:

1. **Supervised execution** of CLI tools (no fire-and-forget).
2. **Error / stall detection** (failed, stalled, slow).
3. **Explicit approval protocol** for tools that normally prompt for user input.
4. **How the TUI must display** stalled tools, failures, and pending approvals.

The instructions in this document are **authoritative**. When editing the repo, treat this as the single source of truth for headless CLI behavior.

---

## 1. Core Concepts & Status Model

### 1.1 Execution Status

Extend the notion of execution/task status to support the following values:

- `queued`
- `running`
- `completed`
- `failed`
- `failed_timeout`
- `stalled`              # no output / heartbeat beyond threshold
- `waiting_approval`     # tool paused for user decision
- `cancelled`            # explicitly cancelled by orchestrator/user

These statuses MUST be used consistently:

- Stored in the **SQLite state backend** (see §2).
- Exposed via **StateClient / ExecutionInfo** (see §3).
- Reflected in **TUI panels** (see §6).

### 1.2 Heartbeats & Output Timestamps

Every supervised CLI execution MUST track:

- `last_output_at`     – last time stdout/stderr produced a line.
- `last_heartbeat_at`  – last time a structured `heartbeat` event was seen (if any).

These are used to distinguish between:

- Normal work vs. potential stall.
- Tools that are chatty vs. tools that are silent but still alive.

### 1.3 Approval Requests

A **headless** tool MUST NOT block on interactive stdin.

Instead it MUST, when it needs a decision:

- Emit a structured `approval_needed` event (see §4).
- Transition execution status to `waiting_approval`.
- Allow the orchestrator / worker to stop or poll for a decision.

Approvals are stored in a dedicated `approvals` table and surfaced in the UI.

---

## 2. SQLite Schema Changes

Modify the existing SQLite backend (`sqlite_state_backend.py`) so that the database schema supports headless supervision and approvals.

### 2.1 `uet_executions` table

**Current definition** (simplified):

```sql
CREATE TABLE IF NOT EXISTS uet_executions (
    execution_id TEXT PRIMARY KEY,
    phase_name   TEXT,
    started_at   TIMESTAMP,
    completed_at TIMESTAMP,
    status       TEXT,
    metadata     JSON
);
````

**AI MUST update this table** to include additional monitoring fields:

```sql
ALTER TABLE uet_executions
    ADD COLUMN tool_name         TEXT          DEFAULT NULL;
ALTER TABLE uet_executions
    ADD COLUMN last_output_at    TIMESTAMP     DEFAULT NULL;
ALTER TABLE uet_executions
    ADD COLUMN last_heartbeat_at TIMESTAMP     DEFAULT NULL;
ALTER TABLE uet_executions
    ADD COLUMN last_error        TEXT          DEFAULT NULL;
```

> Implementation note for AI:
> Use standard SQLite “schema migration” pattern if necessary (create temp table, copy, drop, rename) while preserving existing data.

### 2.2 `uet_tasks` table

No mandatory new columns are required for this spec, but **tasks MAY adopt the same extended status model** in §1.1.

* AI SHOULD ensure any `status` checks are robust against new values (`stalled`, `waiting_approval`, etc.).

### 2.3 `patch_ledger` table

No schema changes required for this spec.

### 2.4 New `approvals` table

Create the following table:

```sql
CREATE TABLE IF NOT EXISTS approvals (
    approval_id   TEXT PRIMARY KEY,
    tool_name     TEXT NOT NULL,
    execution_id  TEXT NOT NULL,
    question      TEXT NOT NULL,
    options_json  JSON NOT NULL,      -- serialized list of {value, label}
    default_value TEXT,
    status        TEXT NOT NULL,      -- 'pending', 'approved', 'rejected', 'expired'
    chosen_value  TEXT,
    created_at    TIMESTAMP NOT NULL,
    decided_at    TIMESTAMP,
    expires_at    TIMESTAMP,
    FOREIGN KEY (execution_id) REFERENCES uet_executions(execution_id)
);
```

AI MUST:

* Add appropriate initialization logic in `_initialize_schema`.
* Ensure the connection uses `row_factory = sqlite3.Row` as already present.
* Implement basic CRUD helpers for approvals in the SQLite backend or a thin helper module (see §3.3).

---

## 3. StateClient & Backend API Extensions

Update `state_client.py` and `sqlite_state_backend.py` to expose the new information.

### 3.1 Extend `ExecutionInfo`

Current fields (simplified):

```python
class ExecutionInfo:
    """Information about a pipeline execution."""

    execution_id: str
    phase_name: Optional[str]
    status: str
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    metadata: Dict[str, Any]
```

AI MUST extend this to include:

```python
class ExecutionInfo:
    """Information about a pipeline execution."""

    execution_id: str
    phase_name: Optional[str]
    status: str
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    metadata: Dict[str, Any]

    # NEW FIELDS
    tool_name: Optional[str] = None
    last_output_at: Optional[datetime] = None
    last_heartbeat_at: Optional[datetime] = None
    last_error: Optional[str] = None
```

### 3.2 Update `StateBackend.get_executions()`

AI MUST:

* Update the `SELECT` in `SQLiteStateBackend.get_executions()` to pull the new columns from `uet_executions`.
* Populate the new fields when constructing `ExecutionInfo`.
* Ensure default values (`None`) are used when older rows do not have data.

### 3.3 Approvals access methods

Add the following methods to `StateBackend` in `state_client.py`:

```python
class StateBackend(ABC):
    ...

    @abstractmethod
    def get_pending_approvals(self, limit: int = 50) -> List["ApprovalInfo"]:
        """Return pending approvals ordered by created_at ascending."""
        pass

    @abstractmethod
    def update_approval_status(
        self,
        approval_id: str,
        new_status: str,
        chosen_value: Optional[str],
        decided_at: Optional[datetime],
    ) -> None:
        """Update approval status and chosen value."""
        pass
```

Define a simple dataclass for approvals:

```python
@dataclass
class ApprovalInfo:
    approval_id: str
    tool_name: str
    execution_id: str
    question: str
    options: List[Dict[str, str]]  # {value, label}
    default_value: Optional[str]
    status: str
    chosen_value: Optional[str]
    created_at: datetime
    decided_at: Optional[datetime]
    expires_at: Optional[datetime]
```

AI MUST:

* Implement these methods in `SQLiteStateBackend` using the `approvals` table.
* Parse `options_json` into a list of `{value, label}` dicts.
* Ensure all date/time fields are parsed consistently with existing helpers.

---

## 4. Supervisor Wrapper & Event Protocol

Create a reusable **supervisor** for launching CLI tools in headless mode.

### 4.1 New module: `core/cli_supervisor.py` (or similar)

AI MUST create a module (exact path can be adjusted to match existing orchestrator structure) that exposes an API of the form:

```python
def run_cli_tool(
    tool_name: str,
    args: list[str],
    execution_id: str,
    *,
    env: Optional[dict[str, str]] = None,
    hard_timeout_seconds: int = 1800,
    no_output_timeout_seconds: int = 300,
) -> int:
    ...
```

Responsibilities:

1. **Create / update `uet_executions` row**:

   * Insert new row with `execution_id`, `tool_name`, `status='running'`, `started_at=now()`.
2. **Launch the process** with:

   * `HEADLESS=1` in env.
   * stdout/stderr captured and streamed.
3. **Continuously read stdout/stderr**:

   * For each line, update `last_output_at`.
   * If the line is valid JSON, inspect for structured events (below).
4. **Track heartbeats**:

   * If event `{"event":"heartbeat", ...}` is seen:

     * Update `last_heartbeat_at` in `uet_executions`.
5. **Track errors**:

   * If event `{"event":"error", ...}` is seen OR stderr contains obvious errors:

     * Update `last_error` and `status='failed'` if process exits non-zero.
6. **Apply timeouts**:

   * If wall-clock exceeds `hard_timeout_seconds`:

     * Terminate process, set `status='failed_timeout'`.
   * If no stdout/stderr for `no_output_timeout_seconds`:

     * Mark `status='stalled'` (but still allow eventual exit).
7. **Handle approval_needed events** (see §4.2).

### 4.2 Approval event format

When running with `HEADLESS=1`, tools that need a decision MUST emit JSON to stdout (or stderr) in the following format:

```json
{
  "event": "approval_needed",
  "tool": "TOOL_NAME",
  "execution_id": "EXEC-123",
  "approval_id": "AP-00123",
  "question": "Apply these changes to the repo?",
  "options": [
    {"value": "approve", "label": "Approve and apply changes"},
    {"value": "reject", "label": "Reject and discard changes"}
  ],
  "default": "reject",
  "expires_in_seconds": 3600
}
```

The supervisor MUST:

1. Insert a row into `approvals` with `status='pending'` and `expires_at = now() + expires_in_seconds`.
2. Update `uet_executions.status` to `waiting_approval`.
3. Terminate the current process with a special exit code (e.g., `90`) OR keep it alive and allow a worker to poll the DB (implementation detail left to the orchestrator).

The orchestrator logic that handles “resume after approval” is **out of scope** of this spec, but MUST respect:

* `status='waiting_approval'` before the decision,
* `approvals.status` and `chosen_value` when resuming or re-running.

---

## 5. Log Event Structure

The supervisor MUST write **JSONL log entries** to the existing combined log (path derived from config) with at least the following events:

1. `tool_status_change`:

```json
{
  "event": "tool_status_change",
  "tool": "aider",
  "execution_id": "EX-123",
  "status": "failed_timeout",
  "reason": "no heartbeat for 600s",
  "timestamp": "..."
}
```

2. `approval_needed` (as above) – forwarded from the tool.

3. `approval_status_change` (when the user approves/rejects):

```json
{
  "event": "approval_status_change",
  "approval_id": "AP-00123",
  "tool": "open_spec",
  "execution_id": "EX-456",
  "status": "approved",
  "chosen_value": "approve",
  "timestamp": "..."
}
```

The **Tool Health** and **Log Stream** panels will rely on these events.

---

## 6. TUI Updates (User Visibility)

AI MUST update the TUI so that a user can clearly see:

* Which tools are **stalled**, **failed**, or **waiting for approval**.
* How many approvals are pending.
* Where to go to approve or reject.

### 6.1 Tool Health Panel (`tool_health_panel.py`)

Update the `ToolHealthWidget` to:

1. Parse `tool_status_change` events from the log and map them to `ToolStatus.status` values such as:

   * `"ok"`
   * `"warn"`
   * `"error"`
   * `"stalled"`
   * `"waiting_approval"`
2. When any tool is in `waiting_approval`:

   * Show a clear message in the summary area, e.g.

     * `"[yellow]1 tool waiting for approval[/]"`
3. Prefer aggregating recent events by `tool` and `execution_id` rather than raw lines.

The panel MUST remain robust if log entries are missing or malformed.

### 6.2 Dashboard Panel (`dashboard_panel.py`)

Extend the dashboard summary to include:

* Count of executions with `status='stalled'`.
* Count of executions with `status='waiting_approval'`.
* A short textual alert if either count > 0, e.g.:

```text
Pending Approvals: 1
Stalled Executions: 2
```

These counts can be derived via:

* A new `StateBackend` helper method (recommended), OR
* Simple queries inside `SQLiteStateBackend.get_pipeline_summary()` that populate additional derived metadata in `PipelineSummary.metadata` (AI may choose best fit).

### 6.3 Optional: Approvals view

AI MAY (but is not required to in the first pass) implement a small panel (e.g. `approvals_panel.py`) that:

* Uses `StateClient.get_pending_approvals()`.
* Lists pending approvals with:

  * tool, execution, question, options.
* For now, this panel can be **read-only**; actual approval mutation may be done outside the TUI (e.g., via a CLI).

---

## 7. Headless Mode Contract

When `HEADLESS=1` (or an equivalent configuration flag) is present:

1. Tools MUST NOT:

   * Call `input()` or block on stdin.
   * Present interactive prompts that require keypresses.
2. Tools MUST:

   * Either auto-decide (e.g., always “yes” or always “no”), OR
   * Emit `approval_needed` and exit/pause.
3. The orchestrator MUST:

   * Never launch tools directly; always use `run_cli_tool(...)` from the supervisor.
   * Record all status changes and approvals in SQLite and logs.

If a tool cannot be made headless-safe, the orchestrator MUST treat it as **unsupported** in headless mode and fail fast with a clear error.

---

## 8. AI Implementation Instructions

This section is addressed directly to the AI agent editing the repo.

1. **Do not overwrite entire files.**
   Apply minimal, focused edits (patch/diff style) preserving existing doc_ids, comments, and formatting where practical.

2. **Order of work (recommended):**

   1. Update SQLite schema and backend methods (`sqlite_state_backend.py`).
   2. Extend `state_client.py` (ExecutionInfo, ApprovalInfo, StateBackend methods).
   3. Implement `approvals` CRUD in the SQLite backend.
   4. Create `core/cli_supervisor.py` (or equivalent) and replace direct `subprocess` calls in orchestrator code with `run_cli_tool(...)`.
   5. Emit JSONL log events as described.
   6. Update TUI panels (`tool_health_panel.py`, `dashboard_panel.py`) to surface new states.
   7. Run existing tests and add new tests where feasible.

3. **Testing:**

   * Ensure `pytest` tests for TUI (`test_panel_registry.py`, `test_layout_manager.py`, and any orchestrator/state tests) still pass.
   * Add at least minimal tests for:

     * New `SQLiteStateBackend` methods.
     * Parsing of approvals.
     * Handling of new statuses in Tool Health panel.

4. **Backwards compatibility:**

   * Assume the database may already contain rows without the new columns set.
   * All new fields MUST be treated as optional and default to `None` / sensible defaults in Python.

5. **Logging hygiene:**

   * All new log events MUST be valid JSON and written one per line.
   * Keep messages concise and safe to render in the TUI.

---

## 9. Definition of Done

Headless CLI execution is considered **implemented** when:

* All CLI tools used by the orchestrator are launched via the supervisor wrapper.
* The SQLite database records:

  * `tool_name`, `last_output_at`, `last_heartbeat_at`, `last_error` for each execution.
* Approvals can be created and updated via the `approvals` table and StateBackend methods.
* TUI Dashboard and Tool Health panels:

  * Show stalled executions.
  * Show tools waiting for approval.
* Logs contain structured JSON events for:

  * Tool status changes.
  * Approval creation and approval status changes.

At that point, a user running only the **headless** system + TUI will be clearly informed when:

* A CLI has failed or stalled.
* A CLI is waiting for their approval to proceed.

```

```
