Here’s the same pipeline expressed as a **state-machine specification**, no code, just structure and behavior.

---

## 1. State machine overview

**State machine name:** `CodeQualityEscalationStateMachine`
**Scope:** One `run_id` + `workstream_id` for a set of files (Python and/or PowerShell).
**Goal:** Drive scripts through:

1. Baseline checks
2. Mechanical auto-fix
3. AI tiers (Aider → Codex → Claude)
4. Either success or quarantine for human review

The machine operates on a **shared data context** (“context”).

---

## 2. Shared data context

The state machine maintains a context object with at least these fields:

### Identity

* `run_id` – unique identifier for this pipeline execution
* `workstream_id` – identifier of the workstream / phase
* `target_files`:

  * `python_files[]`
  * `powershell_files[]`

### Configuration

* `enable_mechanical_autofix` (bool)
* `enable_aider` (bool)
* `enable_codex` (bool)
* `enable_claude` (bool)
* `strict_mode` (bool)

  * If `true`, style-only issues can still block success.
* `max_attempts_per_agent` (integer, default 1)

  * For now you can treat this as 1 for each tier in your design.

### Attempt tracking

* `attempt_number` (integer)

  * `0` = baseline (no AI)
  * `1` = after Aider
  * `2` = after Codex
  * `3` = after Claude
* `current_agent` (string)

  * `"none" | "aider" | "codex" | "claude"`
* `mechanical_fix_applied` (bool)
* `agent_attempt_counts` (per-agent counters; optional now, useful later)

### Error report data (last run)

* `last_error_report` – structured error data from the most recent pipeline run, including:

  * `hard_error_count` – number of blocking errors (syntax, test failures, type errors, etc.)
  * `style_error_count` – style/format/import-only issues
  * `security_issue_count` – from Bandit / PSScriptAnalyzer etc.
  * `issues_by_category` – map from category to counts
  * `issues_by_tool` – map from tool name to counts
  * `total_issues`
  * `error_categories_present[]` – e.g. `["syntax", "type", "formatting"]`
  * `summary_flags`:

    * `has_hard_fail` (bool)
    * `style_only` (bool: true if all issues are style/format/import)
* `previous_error_report` – previous attempt’s report (if any) for delta comparisons

### AI attempt logs (for audit)

* `ai_attempts[]` – list of:

  * `attempt_number`
  * `agent` (`"aider"`, `"codex"`, `"claude"`)
  * `input_error_report_id`
  * `changed_files[]`
  * `notes`

### Output / finalization

* `final_status` – `"success" | "quarantined" | "infra_failure"`
* `quarantine_path` – folder path if quarantined

---

## 3. States

### 3.1 `S_INIT`

**Purpose:** Initialize context and route to baseline check.

**Entry conditions:**

* State machine started for a new `run_id` / `workstream_id`.
* `target_files` known.

**Entry actions:**

* Set:

  * `attempt_number = 0`
  * `current_agent = "none"`
  * `mechanical_fix_applied = false`
* Clear:

  * `last_error_report`
  * `previous_error_report`
  * `ai_attempts[]`

**Transitions:**

* Unconditionally → `S0_BASELINE_CHECK`

---

### 3.2 `S0_BASELINE_CHECK`

**Purpose:** Run the full error pipeline with no AI involvement.

**Entry conditions:**

* Either from `S_INIT`, or from a previous state needing a fresh baseline on current files.

**Actions:**

1. Invoke **error pipeline** on `target_files`:

   * Python: Ruff, Black (check-only), Mypy, pytest, optional extra tools.
   * PowerShell: PSScriptAnalyzer, Pester.
2. Build a **unified error report**, set as `last_error_report` with:

   * `attempt_number = 0`
   * `current_agent = "none"`
   * `mechanical_fix_applied = false` (or current value if already used)
3. Persist this report (e.g., as `error_report_attempt_0.json`).
4. Optionally update metrics (duration, counts, etc.).

**Transitions (guards):**

1. **No blocking issues**

   * Condition:

     * `last_error_report.has_hard_fail == false`
     * AND (`strict_mode == false` OR `last_error_report.total_issues == 0` OR only allowed categories)
   * Next state: `S_SUCCESS`

2. **Style-only issues and mechanical auto-fix enabled**

   * Condition:

     * `last_error_report.style_only == true`
     * AND `enable_mechanical_autofix == true`
   * Next state: `S0_MECHANICAL_AUTOFIX`

3. **Hard errors or style issues that must block**

   * Condition:

     * `last_error_report.has_hard_fail == true`
     * OR (`strict_mode == true` AND `last_error_report.total_issues > 0`)
   * Next state:

     * If `enable_aider == true`: `S1_AIDER_FIX`
     * Else if `enable_codex == true`: `S2_CODEX_FIX`
     * Else if `enable_claude == true`: `S3_CLAUDE_FIX`
     * Else: `S4_QUARANTINE`

4. **Infrastructure failure in pipeline**

   * Condition:

     * Error pipeline itself fails (e.g., cannot run tools)
   * Next state: `S_ERROR_INFRA`

---

### 3.3 `S0_MECHANICAL_AUTOFIX`

**Purpose:** Apply safe, mechanical fixes (formatting, imports, simple lints) without AI.

**Entry conditions:**

* From `S0_BASELINE_CHECK` when `style_only == true` and auto-fix is allowed.

**Actions:**

1. Analyze `last_error_report` to identify files/tools needing mechanical fixes.

2. Apply configured mechanical fixers (examples):

   * Black in auto-format mode
   * isort (imports)
   * Ruff in fix mode (for safe rules)
   * PowerShell formatting (e.g., Editor Services, if available)

3. Record:

   * `mechanical_fix_applied = true`
   * A mechanical-fix log (file list + tools used)

4. After fixes, set:

   * `previous_error_report = last_error_report` (baseline before fix)

**Transitions:**

* Unconditionally → `S0_MECHANICAL_RECHECK`

---

### 3.4 `S0_MECHANICAL_RECHECK`

**Purpose:** Re-run error pipeline after mechanical fixes.

**Entry conditions:**

* Coming from `S0_MECHANICAL_AUTOFIX`.

**Actions:**

1. Invoke the same error pipeline as in `S0_BASELINE_CHECK` on updated files.
2. Build `last_error_report`:

   * `attempt_number = 0`
   * `current_agent = "none"`
   * `mechanical_fix_applied = true`
3. Persist as, e.g., `error_report_attempt_0b.json`.

**Transitions:**

1. **No blocking issues after mechanical fix**

   * Condition:

     * `last_error_report.has_hard_fail == false`
     * AND (strictness rules satisfied)
   * Next state: `S_SUCCESS`

2. **Remaining errors**

   * Condition:

     * `last_error_report.total_issues > 0` and/or `has_hard_fail == true`
   * Next state:

     * If `enable_aider == true`: `S1_AIDER_FIX`
     * Else if `enable_codex == true`: `S2_CODEX_FIX`
     * Else if `enable_claude == true`: `S3_CLAUDE_FIX`
     * Else: `S4_QUARANTINE`

3. **Infrastructure failure**

   * Next state: `S_ERROR_INFRA`

---

### 3.5 `S1_AIDER_FIX`

**Purpose:** Use Aider as first AI tier to correct remaining issues.

**Entry conditions:**

* Errors still present after baseline/mechanical steps.
* `enable_aider == true`.

**Actions:**

1. Set:

   * `attempt_number = 1`
   * `current_agent = "aider"`
   * `previous_error_report = last_error_report`
2. Construct an **Aider-style error-fix prompt** from `last_error_report`:

   * Files to edit
   * Grouped issues per file
   * Constraints (no broad refactors, etc.)
3. Send prompt and files to Aider, allow it to apply edits.
4. Record AI attempt:

   * Append an entry to `ai_attempts[]` for Aider with:

     * `attempt_number = 1`
     * `agent = "aider"`
     * `input_error_report_id`
     * `changed_files[]` (if known)
     * `notes` (summary)

**Transitions:**

* Unconditionally → `S1_AIDER_RECHECK`
  (Assuming Aider completed successfully; if Aider fails as a tool, go to `S_ERROR_INFRA`.)

---

### 3.6 `S1_AIDER_RECHECK`

**Purpose:** Re-run error pipeline after Aider edits.

**Entry conditions:**

* Aider has completed edits.

**Actions:**

1. Run the full error pipeline on updated files.
2. Build `last_error_report`:

   * `attempt_number = 1`
   * `current_agent = "aider"`
3. Persist as `error_report_attempt_1.json`.

**Transitions:**

1. **Clean after Aider**

   * Condition:

     * `last_error_report.has_hard_fail == false`
     * And strictness rules satisfied
   * Next state: `S_SUCCESS`

2. **Still errors, but Aider made progress** (optional heuristic)

   * Condition:

     * `last_error_report.total_issues < previous_error_report.total_issues`
     * And `agent_attempt_counts["aider"] < max_attempts_per_agent`
   * Next state (if you want multiple Aider passes): `S1_AIDER_FIX` again
   * In your original simple design, you skip this and escalate.

3. **Still errors, escalate**

   * Condition:

     * `last_error_report.total_issues > 0` and/or `has_hard_fail == true`
   * Next state:

     * If `enable_codex == true`: `S2_CODEX_FIX`
     * Else if `enable_claude == true`: `S3_CLAUDE_FIX`
     * Else: `S4_QUARANTINE`

4. **Infrastructure failure**

   * Next state: `S_ERROR_INFRA`

---

### 3.7 `S2_CODEX_FIX`

**Purpose:** Use Codex as second AI tier.

**Entry conditions:**

* Remaining errors after Aider tier or direct from baseline.
* `enable_codex == true`.

**Actions:**

1. Set:

   * `attempt_number = 2`
   * `current_agent = "codex"`
   * `previous_error_report = last_error_report`
2. Build a **Codex-oriented error-fix prompt** from `last_error_report`.
3. Send prompt and files to Codex; let it apply edits.
4. Log AI attempt in `ai_attempts[]` (similar fields as Aider).

**Transitions:**

* Unconditionally → `S2_CODEX_RECHECK`
  (on successful Codex run).

---

### 3.8 `S2_CODEX_RECHECK`

**Purpose:** Re-run error pipeline after Codex edits.

**Actions:**

1. Run error pipeline.
2. Set `last_error_report`:

   * `attempt_number = 2`
   * `current_agent = "codex"`
3. Persist as `error_report_attempt_2.json`.

**Transitions:**

1. **Clean after Codex**

   * Condition:

     * `has_hard_fail == false` and strictness satisfied
   * Next state: `S_SUCCESS`

2. **Still errors, optional second Codex pass**

   * Condition (optional):

     * Improved but not clean, and `agent_attempt_counts["codex"] < max_attempts_per_agent`
   * Next state: `S2_CODEX_FIX`
   * (In your minimal design, skip this and escalate.)

3. **Still errors, escalate to Claude**

   * Condition:

     * `last_error_report.total_issues > 0`
   * Next state:

     * If `enable_claude == true`: `S3_CLAUDE_FIX`
     * Else: `S4_QUARANTINE`

4. **Infrastructure failure**

   * Next state: `S_ERROR_INFRA`

---

### 3.9 `S3_CLAUDE_FIX`

**Purpose:** Use Claude + MCP as the highest AI tier for correction.

**Entry conditions:**

* Remaining errors after Codex or earlier tiers.
* `enable_claude == true`.

**Actions:**

1. Set:

   * `attempt_number = 3`
   * `current_agent = "claude"`
   * `previous_error_report = last_error_report`
2. Prepare a **Claude prompt** with:

   * Summary of `last_error_report`
   * Instructions on using MCP tools:

     * e.g., `lint_python_files`, `lint_ps_scripts`, filesystem, git, etc.
3. Claude enters an **internal loop** (within this state’s conceptual behavior):

   * Reads files via MCP.
   * Edits files via MCP.
   * Calls MCP lint/test tools to re-evaluate errors.
   * Iterates until:

     * MCP reports zero blocking issues; or
     * Hit internal iteration limit; or
     * Claude decides remaining issues are unfixable safely.
4. Record AI attempt in `ai_attempts[]`.

**Transitions:**

* Unconditionally (after Claude finishes) → `S3_CLAUDE_RECHECK`
  (for a “canonical” external pipeline run).

---

### 3.10 `S3_CLAUDE_RECHECK`

**Purpose:** Final external error pipeline run after Claude edits.

**Actions:**

1. Run the same error pipeline as baseline on Claude’s final file versions.
2. Set `last_error_report`:

   * `attempt_number = 3`
   * `current_agent = "claude"`
3. Persist as `error_report_attempt_3.json`.

**Transitions:**

1. **Clean after Claude**

   * Condition:

     * `has_hard_fail == false` and strictness rules satisfied
   * Next state: `S_SUCCESS`

2. **Still errors after full escalation**

   * Condition:

     * `last_error_report.total_issues > 0`
   * Next state: `S4_QUARANTINE`

3. **Infrastructure failure**

   * Next state: `S_ERROR_INFRA`

---

### 3.11 `S4_QUARANTINE`

**Purpose:** Package the final code + reports for human review.

**Entry conditions:**

* Errors remain after all enabled tiers (baseline → mechanical → Aider → Codex → Claude).

**Actions:**

1. Create a dedicated **quarantine folder** for this run, e.g. under `Quarantine/`.
2. Copy or write:

   * Final script versions.
   * All error reports:

     * Baseline (0, 0b)
     * After Aider (1)
     * After Codex (2)
     * After Claude (3)
   * `ai_attempts` summary.
   * `metadata`:

     * `run_id`, `workstream_id`
     * Timestamps
     * Tool versions
     * Enabled tiers
     * Final error counts
3. Set:

   * `quarantine_path` = the folder path
   * `final_status = "quarantined"`

**Transitions:**

* Terminal state. No further transitions (unless you design a separate human-review sub-machine).

---

### 3.12 `S_SUCCESS`

**Purpose:** Signal that the script passed all checks and can rejoin the normal pipeline.

**Entry conditions:**

* Some error pipeline run returned no blocking issues (and strictness conditions are met).

**Actions:**

1. Set `final_status = "success"`.
2. Emit a success event / record to the orchestrator:

   * include `run_id`, `workstream_id`, `attempt_number`, `current_agent`, and final `last_error_report` (which should be clean).
3. Optionally:

   * Attach success metadata to the main pipeline state so later stages know this has cleared quality gates.

**Transitions:**

* Terminal state for this `run_id` in this state machine.

---

### 3.13 `S_ERROR_INFRA` (optional but recommended)

**Purpose:** Capture infrastructure/tool failures (not code quality failures).

**Entry conditions:**

* Any upstream state detects:

  * Lint/test tools could not run.
  * MCP server failures that prevent evaluation.
  * Other operational issues.

**Actions:**

1. Record an infra error event with:

   * Which tool / subsystem failed.
   * Logs / messages.
2. Optionally:

   * Quarantine current files + partial reports.
3. Set:

   * `final_status = "infra_failure"`

**Transitions:**

* Terminal state (unless you design retries).

---

If you’d like, I can next:

* Turn this spec into a **compact state-transition table** (rows: current state; columns: condition; next state; actions), or
* Write an English “operating contract” for Codex/Claude that tells them exactly how to implement this state machine in your existing SQLite state layer and tool adapter system (still no executable code).
