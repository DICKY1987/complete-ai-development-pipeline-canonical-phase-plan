---
doc_id: DOC-PAT-GUICODEX-215
---

• High-Level Summary

  - Major runtime modules: engine/orchestrator, engine/adapters
    (aider/codex/tests/git), engine/state_store, engine/queue,
    error/engine, and the shared state/observability stack in
    modules/core-state + core/* UI infra (file lifecycle, tool
    health, error/quarantine, events).
  - Primary outputs: per-job log files and error reports, JobResult
    JSON payloads, SQLite tables (runs, workstreams, step_attempts,
    events, errors, patches, job_queue, file_lifecycle,
    tool_health_metrics, error_records, uet_events, jobs),
    validation caches, and structured error/pattern reports.
  - Cross-module visuals: global “Pipeline Radar” (runs/
    workstreams/jobs over time), “Event Stream” (events/
    uet_events), “File Lifecycle” (file_lifecycle + tool
    touches), “Tool Health” (tool_health_metrics), “Error/
    Quarantine” (error_records + adapter error reports).

  ## Module: engine/orchestrator/orchestrator.py

  Role: CLI/entrypoint that loads a job JSON, routes to the right
  adapter, and writes state updates via JobStateStore.

  ### Outputs

  | Output ID | Type | Source (file/DB/API) | Key Fields / Schema
  (approx) |
  |-----------|------|----------------------|----------------------
  --------|
  | ORC-1 | log_text | stdout/stderr from python -m
  engine.orchestrator run-job ... | [Orchestrator] lines: job_id,
  tool, workstream_id, status transitions, exit_code, duration |
  | ORC-2 | job_result (in-memory/propagated) | return value
  JobResult | exit_code, duration_s, success, stdout (truncated),
  stderr (truncated), error_report_path |
  | ORC-3 | state_update | JobStateStore.update_job_result →
  SQLite .worktrees/pipeline_state.db | step_attempts: job_id (in
  result_json), status, exit_code, duration_s, stdout_preview,
  stderr_preview; events: job.completed payload |

  ### Suggested Visuals (Tiles)

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | JobRunConsoleTile | ORC-1 | Live log viewer | Stream
  orchestrator prints + adapter tail for bottom terminal pane |
  | JobResultSummaryTile | ORC-2, ORC-3 | Status chips + key
  metrics | Show exit_code, duration, success flag, error_report
  link |
  | JobStateUpdateTile | ORC-3 | Timeline/table | Latest job status
  transitions and event payloads |

  ### Generic Output Example

  [Orchestrator] Starting job: job-2025-11-20-001
  [Orchestrator] Tool: aider
  [Orchestrator] Workstream: ws-PH07-refactor-path-resolver
  [Orchestrator] Marked job as running: job-2025-11-20-001
  [Orchestrator] Updated state store with result
  [Orchestrator] Job completed: job-2025-11-20-001
  [Orchestrator] Exit code: 0
  [Orchestrator] Duration: 12.34s
  [Orchestrator] Success: True

  ## Module: engine/adapters/aider_adapter.py

  Role: Builds/runs Aider command, writes job log and error report,
  returns JobResult.

  ### Outputs

  | Output ID | Type | Source (file/DB/API) | Key Fields / Schema
  (approx) |
  |-----------|------|----------------------|----------------------
  --------|
  | AID-1 | log_text | job["paths"]["log_file"] (e.g., logs/<ws>/
  job-...log) | headers, command, working_dir, STDOUT, STDERR,
  exit_code |
  | AID-2 | json_report | job["paths"]["error_report"] (on non-
  zero exit) | job_id, tool="aider", exit_code, summary, details[],
  workstream_id |
  | AID-3 | job_result | return JobResult | exit_code, duration_s,
  stdout/snippets, stderr/snippets, error_report_path |

  ### Suggested Visuals (Tiles)

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | AiderLogTile | AID-1 | Raw log viewer | Scrollable log with
  STDERR highlight |
  | AiderErrorReportTile | AID-2 | JSON inspector | Show structured
  failure details |
  | AiderRunStatsTile | AID-3 | Mini-cards | Exit code, duration,
  timeout/err badges |

  ### Generic Output Example

  === Aider Job: job-2025-11-20-001 ===
  Command: aider --message-file PHASE_DEV_DOCS/
  AIDER_INSTRUCTIONS_PH07.txt --yes-always --no-suggest-shell-
  commands
  Working dir: C:/Users/richg/ALL_AI/Complete AI Development
  Pipeline - Canonical Phase Plan

  === STDOUT ===
  Applied patch to core/planning/planner.py
  === STDERR ===
  (empty)

  === Exit Code: 0 ===

  ## Module: engine/adapters/codex_adapter.py

  Role: Runs GitHub Copilot CLI job (escalation/alt AI path).

  ### Outputs

  | Output ID | Type | Source | Key Fields |
  |-----------|------|--------|------------|
  | COD-1 | log_text | job["paths"]["log_file"] | same structure as
  AID-1 |
  | COD-2 | json_report | job["paths"]["error_report"] | job_id,
  tool="codex", exit_code, summary, details[], workstream_id |
  | COD-3 | job_result | return JobResult | exit_code, duration_s,
  stdout/stderr snippets |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | CodexLogTile | COD-1 | Raw log viewer | Focus on Copilot CLI
  output |
  | CodexEscalationTile | COD-2 | Table/JSON | Show why escalation
  triggered and details |
  | CodexRunStatsTile | COD-3 | Cards | Duration vs Aider; exit
  distribution |

  ### Generic Output Example

  === Codex Job: job-2025-11-20-001-escalated-codex ===
  Command: gh copilot suggest --target shell "Fix the issue:
  failing pytest"
  === STDOUT ===
  copilot> Suggestion applied to tests/test_api.py
  === STDERR ===
  (empty)
  === Exit Code: 0 ===

  ## Module: engine/adapters/tests_adapter.py

  Role: Executes test runners, parses summaries, writes error
  report on failure.

  ### Outputs

  | Output ID | Type | Source | Key Fields |
  |-----------|------|--------|------------|
  | TST-1 | log_text | job["paths"]["log_file"] | command, STDOUT/
  STDERR, exit_code, embedded Test Summary JSON |
  | TST-2 | json_report | job["paths"]["error_report"] (when fail/
  timeout) | job_id, tool="tests", exit_code, summary string,
  test_results {passed, failed, skipped, total}, details[] |
  | TST-3 | job_result | return JobResult with
  metadata=test_summary | exit_code, duration_s, stdout/stderr
  snippets, metadata summary |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | TestRunTile | TST-1 | Log + badges | Show failing tests
  highlighted |
  | TestFailureReportTile | TST-2 | Table/JSON | Failures by file/
  test id |
  | TestSummaryTile | TST-3 | Bar/stacked chips | passed/failed/
  skipped counts, duration |

  ### Generic Output Example

  === Tests Job: job-2025-11-20-004 ===
  Command: pytest -q
  === STDOUT ===
  3 passed, 1 failed, 1 skipped in 12.34s
  === STDERR ===
  tests/test_api.py::test_returns_200 AssertionError: expected 200
  got 500

  === Test Summary ===
  {
    "total": 5,
    "passed": 3,
    "failed": 1,
    "skipped": 1,
    "errors": 0
  }
  === Exit Code: 1 ===

  ## Module: engine/adapters/git_adapter.py

  Role: Runs git operations non-interactively.

  ### Outputs

  | Output ID | Type | Source | Key Fields |
  |-----------|------|--------|------------|
  | GIT-1 | log_text | job["paths"]["log_file"] | command, STDOUT/
  STDERR, exit_code |
  | GIT-2 | json_report | job["paths"]["error_report"] on failure |
  job_id, tool="git", exit_code, summary, git_command, details[] |
  | GIT-3 | job_result | return JobResult | exit_code, duration_s,
  stdout/stderr snippets |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | GitOpsTile | GIT-1 | Raw log viewer | Show git output and
  conflicts |
  | GitErrorTile | GIT-2 | Table | Command, exit code, stderr lines
  |
  | GitOutcomeTile | GIT-3 | Status chips | success/fail/timeout,
  duration |

  ### Generic Output Example

  === Git Job: job-2025-11-20-007 ===
  Command: git status --short
  === STDOUT ===
   M engine/orchestrator/orchestrator.py
  ?? new_file.txt
  === STDERR ===
  (empty)
  === Exit Code: 0 ===

  ## Module: engine/state_store/job_state_store.py

  Role: Adapter over pipeline DB for job-centric reads/writes (uses
  modules/core-state/m010003_db + crud).

  ### Outputs

  | Output ID | Type | Source | Key Fields / Schema (approx) |
  |-----------|------|--------|------------------------------|
  | ST-1 | db_table | SQLite .worktrees/pipeline_state.db → runs |
  run_id, status, created_at, updated_at, metadata_json |
  | ST-2 | db_table | workstreams | ws_id, run_id, status,
  depends_on, metadata_json |
  | ST-3 | db_table | step_attempts (jobs stored here) | id,
  run_id, ws_id, step_name=tool, status (running/completed/
  failed/timeout), started_at, completed_at, result_json{job_id,
  exit_code, duration_s, stdout_preview, stderr_preview, metadata}
  |
  | ST-4 | db_table | events via record_event | id,
  timestamp, run_id, ws_id, event_type (e.g., job.completed),
  payload_json{job_id,status,exit_code,duration_s} |
  | ST-5 | db_table | errors (deduped) | error_code, signature,
  message, count, context_json, first_seen_at, last_seen_at |
  | ST-6 | db_table | patches (from CRUD) | patch_file, diff_hash,
  files_modified[], validated/applied flags, timestamps |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | RunSummaryTile | ST-1 | Cards/table | Recent runs with status +
  updated_at |
  | WorkstreamListTile | ST-2 | Table + dependency badges | ws_id,
  status, depends_on |
  | JobAttemptsTile | ST-3 | Table + sparkline | jobs per run with
  status/exit/duration |
  | EventStreamTile | ST-4 | Live list | job.completed and other
  events |
  | PatchHistoryTile | ST-6 | List | patch files, hashes,
  validated/applied flags |

  ### Generic Output Example

  {
    "id": 42,
    "run_id": "run-20251120-001",
    "ws_id": "ws-PH07-refactor-path-resolver",
    "step_name": "aider",
    "status": "completed",
    "started_at": "2025-11-20T10:03:01Z",
    "completed_at": "2025-11-20T10:03:45Z",
    "result": {
      "job_id": "job-2025-11-20-001",
      "exit_code": 0,
      "duration_s": 44.1,
      "stdout_preview": "Applied patch...",
      "stderr_preview": "",
      "metadata": {}
    }
  }

  ## Module: engine/queue (job_queue.py, queue_manager.py,
  worker_pool.py, escalation.py)

  Role: Async priority queue with persistence, worker pool
  execution, retry/escalation logic.

  ### Outputs

  | Output ID | Type | Source | Key Fields / Schema |
  |-----------|------|--------|---------------------|
  | Q-1 | db_table | SQLite pipeline.db → job_queue | job_id,
  job_data JSON, priority, status (queued/waiting/running/
  retry/completed/failed/cancelled), depends_on[], retry_count,
  max_retries, queued_at, started_at, completed_at, metadata |
  | Q-2 | metrics/map | JobQueue.get_stats() | queued, waiting,
  running, completed, failed, total |
  | Q-3 | dict | QueueManager.get_job_status() | job_id, status,
  priority, retry_count, queued_at, started_at (if running),
  depends_on (if waiting) |
  | Q-4 | policy map | EscalationManager.rules |
  on_failure/on_timeout targets, escalate_priority,
  max_retries_before_escalation |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | JobQueueTile | Q-1, Q-2 | Table + counters | Priority/status
  grid with counts |
  | JobStatusDetailTile | Q-3 | Detail card | Selected job
  lifecycle + retries |
  | EscalationRulesTile | Q-4 | Config viewer | Show escalation
  chains per tool |
  | WorkerPoolTile | Q-2 | Mini dashboard | Active workers, running
  count (from WorkerPool.get_status) |

  ### Generic Output Example

  {
    "job_id": "job-2025-11-20-001",
    "priority": 1,
    "status": "running",
    "queued_at": "2025-11-20T10:00:00",
    "started_at": "2025-11-20T10:00:05",
    "retry_count": 0,
    "depends_on": ["job-2025-11-19-099"]
  }

  ## Module: error/engine (error_engine.py, error_state_machine,
  pipeline service/context)

  Role: Plugin-based detection pipeline with state machine
  escalation; produces normalized error reports and caches.

  ### Outputs

  | Output ID | Type | Source | Key Fields / Schema |
  |-----------|------|--------|---------------------|
  | ERR-1 | json_report (in-memory/return) | run_error_pipeline
  | summary {total_issues, issues_by_tool, issues_by_category,
  has_hard_fail, total_errors, total_warnings, style_only},
  issues[] {tool, path, line, column, code, category, severity,
  message}, outputs[] {input, output}, run_id, workstream_id,
  attempt_number, ai_agent |
  | ERR-2 | file_cache | .state/validation_cache.json | path →
  {hash, last_checked_utc, status} |
  | ERR-3 | json_context | .state/error_pipeline/<run>/
  <ws>/context.json (or ERROR_PIPELINE_DB) | current_state,
  workstream_id, run_id, attempt_number, last_error_report,
  mechanical_fix_applied, current_agent |
  | ERR-4 | json_report files | .state/error_pipeline/<run>/<ws>/
  error_reports/error_report_attempt_<n>.json | attempt metadata +
  normalized issues/summary |
  | ERR-5 | db_table (optional sqlite path) | modules/core-state/
  m010003_db_sqlite tables (runs, workstreams, step_attempts,
  events, errors) when ERROR_PIPELINE_DB set | event payloads for
  error reports/AI attempts |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | ErrorScanSummaryTile | ERR-1 | Donut + table | Issues by
  category/tool, hard-fail flag |
  | ErrorContextTile | ERR-3 | State machine timeline |
  Current_state, attempt_number, agent |
  | ErrorReportsTile | ERR-4 | List/JSON viewer | Per-attempt
  reports with summaries |
  | ValidationCacheTile | ERR-2 | Table | Files, hash,
  last_checked, status (cached vs rechecked) |

  ### Generic Output Example

  {
    "summary": {
      "total_issues": 4,
      "issues_by_tool": {"ruff": 3, "pytest": 1},
      "issues_by_category": {"style": 3, "test_failure": 1},
      "has_hard_fail": true,
      "total_errors": 1,
      "total_warnings": 3
    },
    "issues": [
      {"tool": "pytest", "path": "tests/test_api.py", "line": 18,
  "code": "AssertionError", "category": "test_failure", "severity":
  "error", "message": "expected 200 got 500"}
    ]
  }

  ## Module: modules/core-state (db, crud, events) — backing store
  for engine + UI infra

  Role: SQLite helper layer (.worktrees/pipeline_state.db default)
  with CRUD over runs/workstreams/step_attempts/errors/events/
  patches and event helpers.

  ### Outputs

  | Output ID | Type | Source | Key Fields / Schema |
  |-----------|------|--------|---------------------|
  | CS-1 | db_table | runs, workstreams | run_id/ws_id, status,
  timestamps, metadata_json |
  | CS-2 | db_table | step_attempts | run_id, ws_id, step_name,
  status, started_at, completed_at, result_json |
  | CS-3 | db_table | errors (deduped) | error_code, signature,
  message, context_json, count, first_seen_at, last_seen_at |
  | CS-4 | db_table | events | id, timestamp, run_id, ws_id,
  event_type, payload_json |
  | CS-5 | db_table | patches | patch_file, diff_hash,
  files_modified[], validated/applied, created_at |
  | CS-6 | event helper | get_events_since, get_recent_events |
  filters by last_event_id/limit; payload JSON expanded |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | StateDBBrowserTile | CS-1..CS-5 | Table explorer | Quick DB
  browser per table |
  | EventDeltaTile | CS-4/CS-6 | Live tail | New events since
  cursor |
  | PatchAuditTile | CS-5 | List | Patches with validated/applied
  flags |

  ### Generic Output Example

  {
    "event_type": "job.completed",
    "timestamp": "2025-11-20T10:03:45Z",
    "run_id": "run-20251120-001",
    "ws_id": "ws-PH07-refactor-path-resolver",
    "payload": {
      "job_id": "job-2025-11-20-001",
      "tool": "aider",
      "status": "completed",
      "exit_code": 0,
      "duration_s": 44.1
    }
  }

  ## Module: core UI Infrastructure (file_lifecycle,
  tool_instrumentation, error_records, ui_clients)

  Role: Observability layer for GUI/TUI panels; writes to same
  SQLite DB using extended tables from schema/schema.sql.

  ### Outputs

  | Output ID | Type | Source | Key Fields / Schema |
  |-----------|------|--------|---------------------|
  | UI-1 | db_table | file_lifecycle | file_id, current_path,
  origin_path, file_role, current_state (discovered → quarantined),
  workstream_id, job_id, run_id, timestamps, quarantine_reason,
  metadata_json |
  | UI-2 | db_table | file_state_history | file_id, state,
  timestamp |
  | UI-3 | db_table | file_tool_touches | file_id, tool_id,
  tool_name, action, status, error_message, timestamp |
  | UI-4 | db_table | tool_health_metrics (via
  tool_instrumentation) | tool_id, display_name, category, status,
  status_reason, last_successful_invocation, success_count,
  failure_count, success_rate, mean_latency, p95_latency,
  queue_length, updated_at |
  | UI-5 | db_table | error_records (via error_records.py) |
  error_id, entity_type, file_id/job_id/ws_id/tool_id, severity,
  category, human_message, technical_details, recommendation,
  occurrence_count, quarantine_path, can_retry, auto_fix_available,
  timestamps |
  | UI-6 | db_table | uet_events (from event bus) | event_type,
  worker_id, task_id, run_id, workstream_id, timestamp,
  payload_json |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | FileLifecycleTile | UI-1, UI-2 | Table + state timeline | File
  state, role, quarantine flags |
  | FileToolTouchesTile | UI-3 | List/table | Recent tool touches
  per file |
  | ToolHealthTile | UI-4 | Health cards + sparkline | Status
  (healthy/degraded), success rate, latency |
  | ErrorQuarantineTile | UI-5 | Table + filters | Error severity/
  category, occurrence count, retry/auto-fix flags |
  | EventStreamTile (UI) | UI-6 | Live event list | Worker/task/run
  events with payload snippet |

  ### Generic Output Example

  {
    "tool_id": "aider",
    "status": "healthy",
    "success_rate": 0.92,
    "success_count": 12,
    "failure_count": 1,
    "mean_latency": 35.4,
    "p95_latency": 42.5,
    "last_successful_invocation": "2025-11-26T09:14:00Z",
    "updated_at": "2025-11-26T09:14:00Z"
  }

  ## Module: schema/jobs (job.schema.json + examples)

  Role: Contract for all job inputs consumed by orchestrator/
  ### Outputs

  | Output ID | Type | Source | Key Fields / Schema |
  |-----------|------|--------|---------------------|
  {repo_root, working_dir, log_file, error_report}, metadata
  {retry_policy, timeout_seconds, max_retries, message_file,
  files_scope[]} |
  | JOB-2 | job_example | schema/jobs/examples/*.json | concrete
  sample jobs with log/error paths and metadata |

  ### Suggested Visuals

  | Tile Name | Uses Output IDs | Visual Type | Description |
  |-----------|-----------------|-------------|-------------|
  | JobSpecTile | JOB-1 | Schema viewer | Render required fields /
  enums |
  | JobExampleTile | JOB-2 | JSON viewer | Sample job payloads for
  quick launch |

  ### Generic Output Example

  {
    "job_id": "job-2025-11-20-001",
    "tool": "aider",
    "paths": {
      "log_file": "logs/ws-PH07-refactor-path-resolver/job-2025-11-
  20-001.log",
      "error_report": "logs/ws-PH07-refactor-path-resolver/job-
  2025-11-20-001.error.json"
    },
    "metadata": {
      "retry_policy": "escalate_to_codex",
      "timeout_seconds": 600,
      "files_scope": ["core/planning/planner.py", "core/planning/
  archive.py"]
    }
  }

  Natural next steps: Wire each tile to the noted log/error/report/
  DB sources; start with generic JSON/log viewers, then layer
  tables/timelines for queue, state store, error/quarantine, file
  lifecycle, and tool health.


› convert response to file, put here:"C:
  \Users\richg\ALL_AI\Complete AI Development Pipeline – Canonical
  Phase Plan"


• Added module_outputs_and_visuals.md (+379 -0)
      1 +**High-Level Summary**
      2 +- Major runtime modules: `engine/orchestrator`, `engine/ad
         apters` (aider/codex/tests/git), `engine/state_store`, `en
         gine/queue`, `error/engine`, and the shared state/observab
         ility stack in `modules/core-state` + `core/*` UI infra (f
         ile lifecycle, tool health, error/quarantine, events).
      3 +- Primary outputs: per-job log files and error reports, `J
         obResult` JSON payloads, SQLite tables (`runs`, `workstrea
         ms`, `step_attempts`, `events`, `errors`, `patches`, `job_
         queue`, `file_lifecycle`, `tool_health_metrics`, `error_re
         cords`, `uet_events`, `jobs`), validation caches, and stru
         ctured error/pattern reports.
      4 +- Cross-module visuals: global “Pipeline Radar” (runs/work
         streams/jobs over time), “Event Stream” (events/uet_events
         ), “File Lifecycle” (file_lifecycle + tool touches), “Tool
          Health” (tool_health_metrics), “Error/Quarantine” (error_
         records + adapter error reports).
      5 +
      6 +## Module: engine/orchestrator/orchestrator.py
      7 +**Role**: CLI/entrypoint that loads a job JSON, routes to
         the right adapter, and writes state updates via `JobStateS
         tore`.
      8 +
      9 +### Outputs
     10 +| Output ID | Type | Source (file/DB/API) | Key Fields / S
         chema (approx) |
     11 +|-----------|------|----------------------|---------------
         ---------------|
     12 +| ORC-1 | log_text | stdout/stderr from `python -m engine.
         orchestrator run-job ...` | `[Orchestrator]` lines: job_id
         , tool, workstream_id, status transitions, exit_code, dura
         tion |
     13 +| ORC-2 | job_result (in-memory/propagated) | return value
          `JobResult` | exit_code, duration_s, success, stdout (tru
         ncated), stderr (truncated), error_report_path |
     14 +| ORC-3 | state_update | `JobStateStore.update_job_result`
          → SQLite `.worktrees/pipeline_state.db` | `step_attempts`
         : job_id (in result_json), status, exit_code, duration_s,
         stdout_preview, stderr_preview, metadata; `events`: `job.c
         ompleted` payload |
     15 +
     16 +### Suggested Visuals (Tiles)
     17 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
     18 +|-----------|-----------------|-------------|-------------
         |
     19 +| JobRunConsoleTile | ORC-1 | Live log viewer | Stream orc
         hestrator prints + adapter tail for bottom terminal pane |
     20 +| JobResultSummaryTile | ORC-2, ORC-3 | Status chips + key
          metrics | Show exit_code, duration, success flag, error_r
         eport link |
     21 +| JobStateUpdateTile | ORC-3 | Timeline/table | Latest job
          status transitions and event payloads |
     22 +
     23 +### Generic Output Example
     24 +```text
     25 +[Orchestrator] Starting job: job-2025-11-20-001
     26 +[Orchestrator] Tool: aider
     27 +[Orchestrator] Workstream: ws-PH07-refactor-path-resolver
     28 +[Orchestrator] Marked job as running: job-2025-11-20-001
     29 +[Orchestrator] Updated state store with result
     30 +[Orchestrator] Job completed: job-2025-11-20-001
     31 +[Orchestrator] Exit code: 0
     32 +[Orchestrator] Duration: 12.34s
     33 +[Orchestrator] Success: True
     34 +```
     35 +
     36 +## Module: engine/adapters/aider_adapter.py
     37 +**Role**: Builds/runs Aider command, writes job log and er
         ror report, returns `JobResult`.
     38 +
     39 +### Outputs
     40 +| Output ID | Type | Source (file/DB/API) | Key Fields / S
         chema (approx) |
     41 +|-----------|------|----------------------|---------------
         ---------------|
     42 +| AID-1 | log_text | `job["paths"]["log_file"]` (e.g., `lo
         gs/<ws>/job-...log`) | headers, command, working_dir, STDO
         UT, STDERR, exit_code |
     43 +| AID-2 | json_report | `job["paths"]["error_report"]` (on
          non-zero exit) | job_id, tool="aider", exit_code, summary
         , details[], workstream_id |
     44 +| AID-3 | job_result | return `JobResult` | exit_code, dur
         ation_s, stdout/snippets, stderr/snippets, error_report_pa
         th |
     45 +
     46 +### Suggested Visuals (Tiles)
     47 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
     48 +|-----------|-----------------|-------------|-------------
         |
     49 +| AiderLogTile | AID-1 | Raw log viewer | Scrollable log w
         ith STDERR highlight |
     50 +| AiderErrorReportTile | AID-2 | JSON inspector | Show str
         uctured failure details |
     51 +| AiderRunStatsTile | AID-3 | Mini-cards | Exit code, dura
         tion, timeout/err badges |
     52 +
     53 +### Generic Output Example
     54 +```text
     55 +=== Aider Job: job-2025-11-20-001 ===
     56 +Command: aider --message-file PHASE_DEV_DOCS/AIDER_INSTRUC
         TIONS_PH07.txt --yes-always --no-suggest-shell-commands
     57 +Working dir: C:/Users/richg/ALL_AI/Complete AI Development
          Pipeline - Canonical Phase Plan
     58 +
     59 +=== STDOUT ===
     60 +Applied patch to core/planning/planner.py
     61 +=== STDERR ===
     62 +(empty)
     63 +
     64 +=== Exit Code: 0 ===
     65 +```
     66 +
     67 +## Module: engine/adapters/codex_adapter.py
     68 +**Role**: Runs GitHub Copilot CLI job (escalation/alt AI p
         ath).
     69 +
     70 +### Outputs
     71 +| Output ID | Type | Source | Key Fields |
     72 +|-----------|------|--------|------------|
     73 +| COD-1 | log_text | `job["paths"]["log_file"]` | same str
         ucture as AID-1 |
     74 +| COD-2 | json_report | `job["paths"]["error_report"]` | j
         ob_id, tool="codex", exit_code, summary, details[], workst
         ream_id |
     75 +| COD-3 | job_result | return `JobResult` | exit_code, dur
         ation_s, stdout/stderr snippets |
     76 +
     77 +### Suggested Visuals
     78 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
     79 +|-----------|-----------------|-------------|-------------
         |
     80 +| CodexLogTile | COD-1 | Raw log viewer | Focus on Copilot
          CLI output |
     81 +| CodexEscalationTile | COD-2 | Table/JSON | Show why esca
         lation triggered and details |
     82 +| CodexRunStatsTile | COD-3 | Cards | Duration vs Aider; e
         xit distribution |
     83 +
     84 +### Generic Output Example
     85 +```text
     86 +=== Codex Job: job-2025-11-20-001-escalated-codex ===
     87 +Command: gh copilot suggest --target shell "Fix the issue:
          failing pytest"
     88 +=== STDOUT ===
     89 +copilot> Suggestion applied to tests/test_api.py
     90 +=== STDERR ===
     91 +(empty)
     92 +=== Exit Code: 0 ===
     93 +```
     94 +
     95 +## Module: engine/adapters/tests_adapter.py
     96 +**Role**: Executes test runners, parses summaries, writes
         error report on failure.
     97 +
     98 +### Outputs
     99 +| Output ID | Type | Source | Key Fields |
    100 +|-----------|------|--------|------------|
    101 +| TST-1 | log_text | `job["paths"]["log_file"]` | command,
          STDOUT/STDERR, exit_code, embedded `Test Summary` JSON |
    102 +| TST-2 | json_report | `job["paths"]["error_report"]` (wh
         en fail/timeout) | job_id, tool="tests", exit_code, summar
         y string, test_results {passed, failed, skipped, total}, d
         etails[] |
    103 +| TST-3 | job_result | return `JobResult` with `metadata=t
         est_summary` | exit_code, duration_s, stdout/stderr snippe
         ts, metadata summary |
    104 +
    105 +### Suggested Visuals
    106 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    107 +|-----------|-----------------|-------------|-------------
         |
    108 +| TestRunTile | TST-1 | Log + badges | Show failing tests
         highlighted |
    109 +| TestFailureReportTile | TST-2 | Table/JSON | Failures by
          file/test id |
    110 +| TestSummaryTile | TST-3 | Bar/stacked chips | passed/fai
         led/skipped counts, duration |
    111 +
    112 +### Generic Output Example
    113 +```text
    114 +=== Tests Job: job-2025-11-20-004 ===
    115 +Command: pytest -q
    116 +=== STDOUT ===
    117 +3 passed, 1 failed, 1 skipped in 12.34s
    118 +=== STDERR ===
    119 +tests/test_api.py::test_returns_200 AssertionError: expect
         ed 200 got 500
    120 +
    121 +=== Test Summary ===
    122 +{
    123 +  "total": 5,
    124 +  "passed": 3,
    125 +  "failed": 1,
    126 +  "skipped": 1,
    127 +  "errors": 0
    128 +}
    129 +=== Exit Code: 1 ===
    130 +```
    131 +
    132 +## Module: engine/adapters/git_adapter.py
    133 +**Role**: Runs git operations non-interactively.
    134 +
    135 +### Outputs
    136 +| Output ID | Type | Source | Key Fields |
    137 +|-----------|------|--------|------------|
    138 +| GIT-1 | log_text | `job["paths"]["log_file"]` | command,
          STDOUT/STDERR, exit_code |
    139 +| GIT-2 | json_report | `job["paths"]["error_report"]` on
         failure | job_id, tool="git", exit_code, summary, git_comm
         and, details[] |
    140 +| GIT-3 | job_result | return `JobResult` | exit_code, dur
         ation_s, stdout/stderr snippets |
    141 +
    142 +### Suggested Visuals
    143 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    144 +|-----------|-----------------|-------------|-------------
         |
    145 +| GitOpsTile | GIT-1 | Raw log viewer | Show git output an
         d conflicts |
    146 +| GitErrorTile | GIT-2 | Table | Command, exit code, stder
         r lines |
    147 +| GitOutcomeTile | GIT-3 | Status chips | success/fail/tim
         eout, duration |
    148 +
    149 +### Generic Output Example
    150 +```text
    151 +=== Git Job: job-2025-11-20-007 ===
    152 +Command: git status --short
    153 +=== STDOUT ===
    154 + M engine/orchestrator/orchestrator.py
    155 +?? new_file.txt
    156 +=== STDERR ===
    157 +(empty)
    158 +=== Exit Code: 0 ===
    159 +```
    160 +
    161 +## Module: engine/state_store/job_state_store.py
    162 +**Role**: Adapter over pipeline DB for job-centric reads/w
         rites (uses `modules/core-state/m010003_db` + `crud`).
    163 +
    164 +### Outputs
    165 +| Output ID | Type | Source | Key Fields / Schema (approx)
          |
    166 +|-----------|------|--------|-----------------------------
         -|
    167 +| ST-1 | db_table | SQLite `.worktrees/pipeline_state.db`
         → `runs` | run_id, status, created_at, updated_at, metadat
         a_json |
    168 +| ST-2 | db_table | `workstreams` | ws_id, run_id, status,
          depends_on, metadata_json |
    169 +| ST-3 | db_table | `step_attempts` (jobs stored here) | i
         d, run_id, ws_id, step_name=tool, status (running/complete
         d/failed/timeout), started_at, completed_at, result_json{j
         ob_id, exit_code, duration_s, stdout_preview, stderr_previ
         ew, metadata} |
    170 +| ST-4 | db_table | `events` via `record_event` | id, time
         stamp, run_id, ws_id, event_type (e.g., job.completed), pa
         yload_json{job_id,status,exit_code,duration_s} |
    171 +| ST-5 | db_table | `errors` (deduped) | error_code, signa
         ture, message, count, context_json, first_seen_at, last_se
         en_at |
    172 +| ST-6 | db_table | `patches` (from CRUD) | patch_file, di
         ff_hash, files_modified[], validated/applied flags, timest
         amps |
    173 +
    174 +### Suggested Visuals
    175 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    176 +|-----------|-----------------|-------------|-------------
         |
    177 +| RunSummaryTile | ST-1 | Cards/table | Recent runs with s
         tatus + updated_at |
    178 +| WorkstreamListTile | ST-2 | Table + dependency badges |
         ws_id, status, depends_on |
    179 +| JobAttemptsTile | ST-3 | Table + sparkline | jobs per ru
         n with status/exit/duration |
    180 +| EventStreamTile | ST-4 | Live list | job.completed and o
         ther events |
    181 +| PatchHistoryTile | ST-6 | List | patch files, hashes, va
         lidated/applied flags |
    182 +
    183 +### Generic Output Example
    184 +```json
    185 +{
    186 +  "id": 42,
    187 +  "run_id": "run-20251120-001",
    188 +  "ws_id": "ws-PH07-refactor-path-resolver",
    189 +  "step_name": "aider",
    190 +  "status": "completed",
    191 +  "started_at": "2025-11-20T10:03:01Z",
    192 +  "completed_at": "2025-11-20T10:03:45Z",
    193 +  "result": {
    194 +    "job_id": "job-2025-11-20-001",
    195 +    "exit_code": 0,
    196 +    "duration_s": 44.1,
    197 +    "stdout_preview": "Applied patch...",
    198 +    "stderr_preview": "",
    199 +    "metadata": {}
    200 +  }
    201 +}
    202 +```
    203 +
    204 +## Module: engine/queue (job_queue.py, queue_manager.py, w
         orker_pool.py, escalation.py)
    205 +**Role**: Async priority queue with persistence, worker po
         ol execution, retry/escalation logic.
    206 +
    207 +### Outputs
    208 +| Output ID | Type | Source | Key Fields / Schema |
    209 +|-----------|------|--------|---------------------|
    210 +| Q-1 | db_table | SQLite `pipeline.db` → `job_queue` | jo
         b_id, job_data JSON, priority, status (queued/waiting/runn
         ing/retry/completed/failed/cancelled), depends_on[], retry
         _count, max_retries, queued_at, started_at, completed_at,
         metadata |
    211 +| Q-2 | metrics/map | `JobQueue.get_stats()` | queued, wai
         ting, running, completed, failed, total |
    212 +| Q-3 | dict | `QueueManager.get_job_status()` | job_id, s
         tatus, priority, retry_count, queued_at, started_at (if ru
         nning), depends_on (if waiting) |
    213 +| Q-4 | policy map | `EscalationManager.rules` | on_failur
         e/on_timeout targets, escalate_priority, max_retries_befor
         e_escalation |
    214 +
    215 +### Suggested Visuals
    216 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    217 +|-----------|-----------------|-------------|-------------
         |
    218 +| JobQueueTile | Q-1, Q-2 | Table + counters | Priority/st
         atus grid with counts |
    219 +| JobStatusDetailTile | Q-3 | Detail card | Selected job l
         ifecycle + retries |
    220 +| EscalationRulesTile | Q-4 | Config viewer | Show escalat
         ion chains per tool |
    221 +| WorkerPoolTile | Q-2 | Mini dashboard | Active workers,
         running count (from `WorkerPool.get_status`) |
    222 +
    223 +### Generic Output Example
    224 +```json
    225 +{
    226 +  "job_id": "job-2025-11-20-001",
    227 +  "priority": 1,
    228 +  "status": "running",
    229 +  "queued_at": "2025-11-20T10:00:00",
    230 +  "started_at": "2025-11-20T10:00:05",
    231 +  "retry_count": 0,
    232 +  "depends_on": ["job-2025-11-19-099"]
    233 +}
    234 +```
    235 +
    236 +## Module: error/engine (error_engine.py, error_state_mach
         ine, pipeline service/context)
    237 +**Role**: Plugin-based detection pipeline with state machi
         ne escalation; produces normalized error reports and cache
         s.
    238 +
    239 +### Outputs
    240 +| Output ID | Type | Source | Key Fields / Schema |
    241 +|-----------|------|--------|---------------------|
    242 +| ERR-1 | json_report (in-memory/return) | `run_error_pipe
         line` | summary {total_issues, issues_by_tool, issues_by_c
         ategory, has_hard_fail, total_errors, total_warnings, styl
         e_only}, issues[] {tool, path, line, column, code, categor
         y, severity, message}, outputs[] {input, output}, run_id,
         workstream_id, attempt_number, ai_agent |
    243 +| ERR-2 | file_cache | `.state/validation_cache.json` | pa
         th → {hash, last_checked_utc, status} |
    244 +| ERR-3 | json_context | `.state/error_pipeline/<run>/<ws>
         /context.json` (or ERROR_PIPELINE_DB) | current_state, wor
         kstream_id, run_id, attempt_number, last_error_report, mec
         hanical_fix_applied, current_agent |
    245 +| ERR-4 | json_report files | `.state/error_pipeline/<run>
         /<ws>/error_reports/error_report_attempt_<n>.json` | attem
         pt metadata + normalized issues/summary |
    246 +| ERR-5 | db_table (optional sqlite path) | `modules/core-
         state/m010003_db_sqlite` tables (`runs`, `workstreams`, `s
         tep_attempts`, `events`, `errors`) when ERROR_PIPELINE_DB
         set | event payloads for error reports/AI attempts |
    247 +
    248 +### Suggested Visuals
    249 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    250 +|-----------|-----------------|-------------|-------------
         |
    251 +| ErrorScanSummaryTile | ERR-1 | Donut + table | Issues by
          category/tool, hard-fail flag |
    252 +| ErrorContextTile | ERR-3 | State machine timeline | Curr
         ent_state, attempt_number, agent |
    253 +| ErrorReportsTile | ERR-4 | List/JSON viewer | Per-attemp
         t reports with summaries |
    254 +| ValidationCacheTile | ERR-2 | Table | Files, hash, last_
         checked, status (cached vs rechecked) |
    255 +
    256 +### Generic Output Example
    257 +```json
    258 +{
    259 +  "summary": {
    260 +    "total_issues": 4,
    261 +    "issues_by_tool": {"ruff": 3, "pytest": 1},
    262 +    "issues_by_category": {"style": 3, "test_failure": 1},
    263 +    "has_hard_fail": true,
    264 +    "total_errors": 1,
    265 +    "total_warnings": 3
    266 +  },
    267 +  "issues": [
    268 +    {"tool": "pytest", "path": "tests/test_api.py", "line"
         : 18, "code": "AssertionError", "category": "test_failure"
         , "severity": "error", "message": "expected 200 got 500"}
    269 +  ]
    270 +}
    271 +```
    272 +
    273 +## Module: modules/core-state (db, crud, events) — backing
          store for engine + UI infra
    274 +**Role**: SQLite helper layer (`.worktrees/pipeline_state.
         db` default) with CRUD over runs/workstreams/step_attempts
         /errors/events/patches and event helpers.
    275 +
    276 +### Outputs
    277 +| Output ID | Type | Source | Key Fields / Schema |
    278 +|-----------|------|--------|---------------------|
    279 +| CS-1 | db_table | `runs`, `workstreams` | run_id/ws_id,
         status, timestamps, metadata_json |
    280 +| CS-2 | db_table | `step_attempts` | run_id, ws_id, step_
         name, status, started_at, completed_at, result_json |
    281 +| CS-3 | db_table | `errors` (deduped) | error_code, signa
         ture, message, context_json, count, first_seen_at, last_se
         en_at |
    282 +| CS-4 | db_table | `events` | id, timestamp, run_id, ws_i
         d, event_type, payload_json |
    283 +| CS-5 | db_table | `patches` | patch_file, diff_hash, fil
         es_modified[], validated/applied, created_at |
    284 +| CS-6 | event helper | `get_events_since`, `get_recent_ev
         ents` | filters by last_event_id/limit; payload JSON expan
         ded |
    285 +
    286 +### Suggested Visuals
    287 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    288 +|-----------|-----------------|-------------|-------------
         |
    289 +| StateDBBrowserTile | CS-1..CS-5 | Table explorer | Quick
          DB browser per table |
    290 +| EventDeltaTile | CS-4/CS-6 | Live tail | New events sinc
         e cursor |
    291 +| PatchAuditTile | CS-5 | List | Patches with validated/ap
         plied flags |
    292 +
    293 +### Generic Output Example
    294 +```json
    295 +{
    296 +  "event_type": "job.completed",
    297 +  "timestamp": "2025-11-20T10:03:45Z",
    298 +  "run_id": "run-20251120-001",
    299 +  "ws_id": "ws-PH07-refactor-path-resolver",
    300 +  "payload": {
    301 +    "job_id": "job-2025-11-20-001",
    302 +    "tool": "aider",
    303 +    "status": "completed",
    304 +    "exit_code": 0,
    305 +    "duration_s": 44.1
    306 +  }
    307 +}
    308 +```
    309 +
    310 +## Module: core UI Infrastructure (file_lifecycle, tool_in
         strumentation, error_records, ui_clients)
    311 +**Role**: Observability layer for GUI/TUI panels; writes t
         o same SQLite DB using extended tables from `schema/schema
         .sql`.
    312 +
    313 +### Outputs
    314 +| Output ID | Type | Source | Key Fields / Schema |
    315 +|-----------|------|--------|---------------------|
    316 +| UI-1 | db_table | `file_lifecycle` | file_id, current_pa
         th, origin_path, file_role, current_state (discovered → qu
         arantined), workstream_id, job_id, run_id, timestamps, qua
         rantine_reason, metadata_json |
    317 +| UI-2 | db_table | `file_state_history` | file_id, state,
          timestamp |
    318 +| UI-3 | db_table | `file_tool_touches` | file_id, tool_id
         , tool_name, action, status, error_message, timestamp |
    319 +| UI-4 | db_table | `tool_health_metrics` (via `tool_instr
         umentation`) | tool_id, display_name, category, status, st
         atus_reason, last_successful_invocation, success_count, fa
         ilure_count, success_rate, mean_latency, p95_latency, queu
         e_length, updated_at |
    320 +| UI-5 | db_table | `error_records` (via `error_records.py
         `) | error_id, entity_type, file_id/job_id/ws_id/tool_id,
         severity, category, human_message, technical_details, reco
         mmendation, occurrence_count, quarantine_path, can_retry,
         auto_fix_available, timestamps |
    321 +| UI-6 | db_table | `uet_events` (from event bus) | event_
         type, worker_id, task_id, run_id, workstream_id, timestamp
         , payload_json |
    322 +
    323 +### Suggested Visuals
    324 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    325 +|-----------|-----------------|-------------|-------------
         |
    326 +| FileLifecycleTile | UI-1, UI-2 | Table + state timeline
         | File state, role, quarantine flags |
    327 +| FileToolTouchesTile | UI-3 | List/table | Recent tool to
         uches per file |
    328 +| ToolHealthTile | UI-4 | Health cards + sparkline | Statu
         s (healthy/degraded), success rate, latency |
    329 +| ErrorQuarantineTile | UI-5 | Table + filters | Error sev
         erity/category, occurrence count, retry/auto-fix flags |
    330 +| EventStreamTile (UI) | UI-6 | Live event list | Worker/t
         ask/run events with payload snippet |
    331 +
    332 +### Generic Output Example
    333 +```json
    334 +{
    335 +  "tool_id": "aider",
    336 +  "status": "healthy",
    337 +  "success_rate": 0.92,
    338 +  "success_count": 12,
    339 +  "failure_count": 1,
    340 +  "mean_latency": 35.4,
    341 +  "p95_latency": 42.5,
    342 +  "last_successful_invocation": "2025-11-26T09:14:00Z",
    343 +  "updated_at": "2025-11-26T09:14:00Z"
    344 +}
    345 +```
    346 +
    347 +## Module: schema/jobs (job.schema.json + examples)
    348 +**Role**: Contract for all job inputs consumed by orchestr
         ator/adapters.
    349 +
    350 +### Outputs
    351 +| Output ID | Type | Source | Key Fields / Schema |
    352 +|-----------|------|--------|---------------------|
    353 +| JOB-1 | json_schema | `schema/jobs/job.schema.json` | jo
         b_id, workstream_id, tool, command {exe,args[]}, env map,
    356 +### Suggested Visuals
    357 +| Tile Name | Uses Output IDs | Visual Type | Description
         |
    358 +|-----------|-----------------|-------------|-------------
         |
    359 +| JobSpecTile | JOB-1 | Schema viewer | Render required fi
         elds / enums |
    360 +| JobExampleTile | JOB-2 | JSON viewer | Sample job payloa
         ds for quick launch |
    361 +
    362 +### Generic Output Example
    363 +```json
    364 +{
    365 +  "job_id": "job-2025-11-20-001",
    366 +  "tool": "aider",
    367 +  "paths": {
    368 +    "log_file": "logs/ws-PH07-refactor-path-resolver/job-2
         025-11-20-001.log",
    369 +    "error_report": "logs/ws-PH07-refactor-path-resolver/j
         ob-2025-11-20-001.error.json"
    370 +  },
    371 +  "metadata": {
    372 +    "retry_policy": "escalate_to_codex",
    373 +    "timeout_seconds": 600,
    374 +    "files_scope": ["core/planning/planner.py", "core/plan
         ning/archive.py"]
    375 +  }
    376 +}
    377 +```
    378 +
    379 +**Natural next steps**: Wire each tile to the noted log/er
         ror/report/DB sources; start with generic JSON/log viewers
         , then layer tables/timelines for queue, state store, erro
         r/quarantine, file lifecycle, and tool health.