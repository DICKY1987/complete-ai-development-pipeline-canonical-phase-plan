   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   ğŸ“‹ DEVELOPMENT RULES: DO's and DON'Ts

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   âœ… MUST DO - Mandatory Practices

   1. Ground Truth Over Vibes

   DO:

     - âœ… Always verify with CLI commands (git status, pytest, Test-Path)
     - âœ… Base decisions ONLY on observable outputs (exit codes, test results, file existence)
     - âœ… Treat "all tests passed" (e.g., 118/118 passed) as the ONLY success criterion

   DON'T:

     - âŒ Declare success based on "this looks right" or internal confidence
     - âŒ Assume tools did their job without verification
     - âŒ Mark phases "complete" without observable test output

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   2. Atomic Execution & Small Phases

   DO:

     - âœ… Break work into small, verifiable phases (e.g., Phase 1A: Task Queue only)
     - âœ… Each phase creates 1-3 modules max with tests
     - âœ… Use patch-style minimal diffs (+1/-1 changes)
     - âœ… Execute one phase completely before moving to next

   DON'T:

     - âŒ Create giant refactors touching 20+ files
     - âŒ Spend 80k+ tokens on planning without executing atomic steps
     - âŒ Bundle script creation + 4+ docs into one phase
     - âŒ Whole-file rewrites when patches will do

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   3. Mandatory Phase Structure

   DO: Every phase MUST have:

     - âœ… Phase ID & Workstream ID (e.g., ws-pipeline-plus-1a-task-queue)
     - âœ… Objective - Single tight goal
     - âœ… File Scope - Explicit create, modify, read_only lists
     - âœ… Dependencies - What must complete first, what can run parallel
     - âœ… Programmatic Acceptance Tests - PowerShell + pytest checks
     - âœ… Pre-Flight Checks - Verify prerequisites exist before starting

   DON'T:

     - âŒ Start phases without explicit workstream IDs
     - âŒ Proceed without file scope declarations
     - âŒ Skip acceptance test definitions
     - âŒ Ignore dependency ordering

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   4. Self-Healing Execution

   DO:

     - âœ… Run â†’ Inspect â†’ Fix â†’ Re-verify loop
     - âœ… Detect when tools under-deliver (missing files/dirs)
     - âœ… Autonomously repair environment (create missing dirs, files)
     - âœ… Re-run tests after fixes
     - âœ… Only declare success after verification passes

   DON'T:

     - âŒ Stop and wait for humans to fix tool failures
     - âŒ Skip verification after tool execution
     - âŒ Assume success without re-running tests
     - âŒ Ask permission to fix obvious failures (syntax errors, test failures)

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   5. Worktree & Patch Isolation

   DO:

     - âœ… Every workstream in isolated git worktree (.worktrees/ws-*)
     - âœ… All edits captured as unified diff patches
     - âœ… Store patches in .ledger/patches/
     - âœ… Validate patches only touch files in declared scope
     - âœ… Detect oscillation (same diff hash repeating)

   DON'T:

     - âŒ Work in main worktree without isolation
     - âŒ Apply patches touching files outside scope
     - âŒ Skip patch metadata tracking
     - âŒ Ignore oscillation detection

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   6. Operator Mindset

   DO:

     - âœ… Behave like an operator: run commands, inspect outputs, fix environment
     - âœ… Proceed with obvious next safe action (don't ask permission)
     - âœ… Make decisions based on CLI output, not assumptions
     - âœ… Use Get-ChildItem, git status to discover actual state

   DON'T:

     - âŒ Act as passive code generator
     - âŒ Ask "Would you like me to..." for obvious next steps
     - âŒ Create permission bottlenecks
     - âŒ Hallucinate file structure without verifying on disk

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   7. Test-Driven Everything

   DO:

     - âœ… Tests MUST exist before or be created as part of phase
     - âœ… Run deterministic CLI commands (python -m pytest -q tests/test_*.py)
     - âœ… Only accept "all tests green" as completion
     - âœ… Cover core subsystems: task queue, audit, patch manager, validators, adapters

   DON'T:

     - âŒ Complete phases without tests
     - âŒ Skip pytest or filesystem validation
     - âŒ Use conversational reasoning as basis for completion
     - âŒ Declare "tested & verified" without observable test output

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   8. Standard Architecture Layout

   DO: Required directories (Phase 0 creates these):

     - âœ… .tasks/inbox/, .tasks/running/, .tasks/done/, .tasks/failed/
     - âœ… .ledger/patches/
     - âœ… .runs/
     - âœ… schema/migrations/001_add_patches_table.sql
     - âœ… config/router.config.yaml

   DON'T:

     - âŒ Invent new architecture on the fly
     - âŒ Create ad-hoc root-level subsystems
     - âŒ Contradict established queue/ledger/runs structure

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   âŒ ANTI-PATTERNS - Strictly Forbidden

   1. Hallucination of Success

   What Happened:

     - AI declared "Complete âœ…" and "Tested & Verified" while pytest was still running
     - No observable exit code or test output, but claimed specific behaviors passed

   Rule Violated: Ground Truth over Vibes

   Fix: Always wait for test completion, inspect exit codes, verify output

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   2. Planning Loop Trap

   What Happened:

     - 80k+ token planning sessions with no atomic execution
     - Multiple heavyweight Plan() calls consuming 4-5 minutes each
     - No pytest, git worktree, or patch generation

   Rule Violated: Atomic Execution

   Fix: Execute Phase 0 immediately (create one file + test), then iterate

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   3. Permission Bottlenecks

   What Happened:

     - AI repeatedly asked "Would you like me to..."
     - Paused for user input when next step was obvious

   Rule Violated: Operator Mindset

   Fix: Proceed autonomously with obvious safe actions

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   4. Context Pollution

   What Happened:

     - Loading 300+ line specs before any atomic step
     - Designing 20+ workstream plans without executing one
     - Giant refactor intent touching 65+ files

   Rule Violated: Strict Isolation & Atomic Phasing

   Fix: Start with single test fixture, modify one module, validate, iterate

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   5. Trusting Tools Without Verification

   What Happened:

     - Aider told to create dirs/files but didn't
     - AI assumed success without checking filesystem

   Rule Violated: CLI-First, Never Vibes

   Fix: Always verify artifacts exist after tool execution, self-heal if missing

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   6. Declaring Complete Without Programmatic Acceptance

   What Happened:

     - Copied files once, marked "âœ… COMPLETED"
     - No git status, no tests, no validation

   Rule Violated: Test-Driven Everything

   Fix: Run acceptance tests, verify all checks pass before completion

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   ğŸ¯ THE GOLDEN WORKFLOW

     1. Pre-Flight Check
        â†“ Verify prerequisites exist
        â†“ If fail â†’ repair & retry

     2. Execute Atomic Phase
        â†“ Run workstream command (--ws-id)
        â†“ Isolated git worktree
        â†“ Small patch-style changes

     3. Inspect Reality
        â†“ git status
        â†“ Test-Path for required files
        â†“ pytest -q tests/test_*.py

     4. Self-Heal if Needed
        â†“ Detect missing artifacts
        â†“ Create dirs/files directly
        â†“ Fix test failures

     5. Re-Verify
        â†“ Run acceptance tests again
        â†“ All tests green? (e.g., 118/118)

     6. âœ… ONLY THEN: Mark Complete

   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   ğŸ“Š Success Metrics

   A phase is ONLY complete when:

     - âœ… All programmatic tests pass (observable output like 118/118 passed)
     - âœ… All required files/dirs exist (verified via CLI)
     - âœ… Git status is clean or matches expected changes
     - âœ… Patches stored in ledger with metadata
     - âœ… No files touched outside declared scope