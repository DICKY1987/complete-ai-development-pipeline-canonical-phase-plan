Absolutely—these two fit as **first-class “runner types”** under your Capability Catalog. Think of them like Taskfile/Just/doit backends that your resolver can target when a card says “run this via Invoke (Python)” or “run this via Invoke-Build (PowerShell).”

# Where each shines (and why)

* **Invoke (Python):** great for *orchestration* and unit-testable subprocess work via `c.run(...)`, with rich result objects and a strong config precedence model for deterministic behavior. It runs as a CLI or as an embedded library—handy for your headless resolver/executor split.   
  Bonus: **MockContext** lets you test task logic without actually running shell commands—perfect for your L0/L1 gates. 

* **Invoke-Build (PowerShell):** native PS task engine with **incremental tasks** (`-Inputs`/`-Outputs`), **parallelism** (runspaces), and strict **fail-fast** (`$ErrorActionPreference='Stop'`)—excellent for speed + reliability in your Windows/PS paths.   
  It also runs each build in an **isolated script scope**, avoiding session pollution—good for deterministic runs. 

# How to plug them into your cards

Add a `runner` and `argv_template` to the card; your resolver hydrates params and emits an **argv array** (no shell), logs RESOLVE/VERIFY/EXECUTE to the ledger, and your small executor runs it.

**Card → Invoke (Python)**

```yaml
key: cap.docs.build.v1
runner: invoke
argv_template: ["inv","docs","--publish={{publish}}"]
placeholders:
  publish: {required: false, default: "no"}
verify:
  - sh: "python --version"
  - sh: "pip show invoke"
```

Why Invoke here? You get structured `Result` objects from `c.run(...)` and can unit-test this task with **MockContext** in L0/L1.  

**Card → Invoke-Build (PowerShell)**

```yaml
key: cap.ps.build.module.v1
runner: invoke-build
argv_template: ["pwsh","-File",".\\build.ps1","-Task","Build,Test","-Configuration","Release"]
verify:
  - sh: "pwsh -NoLogo -NoProfile -Command \"$PSVersionTable.PSVersion\""
  - sh: "pwsh -NoLogo -NoProfile -Command \"Get-Module InvokeBuild -ListAvailable\""
limits:
  timeout_ms: 300000
```

Why IB here? You can mark tasks incremental (`-Inputs/-Outputs`) and fan out with runspaces for speed; the engine will **stop on any error** for CI-grade reliability.   

# Resolver behavior (deterministic + fast)

* **Choose backend by card** (`runner: invoke|invoke-build|task|just|doit`).
* **Hydrate args** → build **argv** exactly the same for same inputs (no shell joins).
* **VERIFY cache** (tool versions, OS, PATH hash) before execution; log cache hits/misses.
* **Log**: write RESOLVE/VERIFY/EXECUTE with run_id, argv, exit_code to JSONL (.ledger). (Matches your ledger plan.) 

# When to prefer which

* Pick **Invoke** when you want:

  * Pythonic orchestration, embeddable in your agent, and strong testability via **MockContext**.  
  * Deterministic settings via the **config precedence** model (env vars overriding project configs in CI).  
  * Note: Invoke intentionally **does not** do DAG/incremental builds—use it for orchestration, not timestamp-driven rebuilds. 

* Pick **Invoke-Build** when you need:

  * **Incremental speedups** with `-Inputs/-Outputs`. 
  * **Parallel runs** (runspaces) and visualizable DAGs.  
  * **Fail-fast** behavior for CI correctness. 

# Tiny end-to-end example (what your resolver emits)

* **Invoke path:** `["inv","docs","--publish=yes"]` → executor runs; result inspected (stdout/exit) for ledger. (Invoke returns structured results via `c.run(...)`.) 
* **Invoke-Build path:** `["pwsh","-File",".\\build.ps1","-Task","Build,Test"]` → IB enforces error-stop and can skip unchanged work via incremental tasks.  

# Quick adapters you’ll want

* **invoke.adapter.ps1 / py** → normalizes `inv …` outputs to your JSONL schema. (Capture argv, exit, duration.)
* **ib.adapter.ps1** → wraps `build.ps1`/`ib.cmd`, emits the same JSONL fields. (Leverage script-scope isolation.) 

If you’d like, I can draft two ready-to-drop cards (one per runner) plus a minimal resolver snippet that chooses between them and writes the three standard ledger events—so you can A/B them in your current repo layout.
