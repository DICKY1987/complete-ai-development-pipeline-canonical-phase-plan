# Pattern: Batch File Generation from Specification
# Pattern ID: PAT-BATCH-FILE-GEN-001
# Version: 1.0.0
# Category: code_generation
# Status: active

pattern_id: "PAT-BATCH-FILE-GEN-001"
doc_id: "DOC-BATCH-FILE-GEN-001"
name: "batch_file_generation_from_spec"
version: "1.0.0"
category: "code_generation"
status: "active"

metadata:
  created: "2025-11-24"
  author: "UET Framework Team"
  purpose: "Generate multiple related files from specification sources"
  use_case: "Pattern framework file generation"

intent: |
  Generate large batches of related files from specifications using parallel
  execution with per-batch validation. Optimized for consistency, speed, and
  compliance with governance specs.

applicability:
  when_to_use:
    - Generating 50+ files from templates
    - Files have structural relationships (schema → example → test)
    - Need validation at multiple checkpoints
    - Compliance with specs required (PAT-CHECK-001, ID-SYSTEM-SPEC-V1)

  when_not_to_use:
    - Single file generation (use atomic_create)
    - Complex business logic required
    - Manual intervention needed per file

inputs:
  source_specs:
    type: "array"
    required: true
    description: "Source specification files to parse"
    items:
      type: "object"
      properties:
        path:
          type: "string"
        format:
          type: "string"
          enum: ["yaml", "json"]
        spec_type:
          type: "string"
          enum: ["pattern_spec", "schema", "registry"]

  templates:
    type: "object"
    required: true
    description: "Template files for each generation type"
    properties:
      schema_template:
        type: "string"
      example_template:
        type: "string"
      executor_template:
        type: "string"
      test_template:
        type: "string"

  generation_rules:
    type: "object"
    required: true
    description: "Rules and compliance specs"
    properties:
      compliance_specs:
        type: "array"
        items:
          type: "string"
      naming_convention:
        type: "string"
      output_structure:
        type: "object"

  batch_config:
    type: "object"
    required: false
    default:
      batch_size: 10
      parallel_batches: 3
      validation_mode: "per_batch"
    properties:
      batch_size:
        type: "integer"
        minimum: 1
        maximum: 50
      parallel_batches:
        type: "integer"
      validation_mode:
        enum: ["per_file", "per_batch", "end_only"]

outputs:
  generated_files:
    type: "array"
    description: "List of successfully generated files"
    items:
      type: "object"
      properties:
        path:
          type: "string"
        type:
          type: "string"
        doc_id:
          type: "string"
        validation_status:
          type: "string"

  validation_results:
    type: "object"
    properties:
      total_checks:
        type: "integer"
      passed:
        type: "integer"
      failed:
        type: "integer"
      compliance_status:
        type: "string"

  generation_report:
    type: "object"
    properties:
      files_generated:
        type: "integer"
      files_failed:
        type: "integer"
      duration_seconds:
        type: "number"
      batches_processed:
        type: "integer"

execution_steps:
  - step_id: "S1_parse_source_specs"
    description: "Parse all source specifications and extract metadata"
    parallel: false
    actions:
      - action: "load_pattern_index"
        file: "patterns/registry/PATTERN_INDEX.yaml"
        extract:
          - pattern_id
          - doc_id
          - name
          - category

      - action: "load_spec_files"
        directory: "patterns/specs"
        extract:
          - inputs
          - outputs
          - metadata

      - action: "build_generation_matrix"
        output: "generation_matrix"
        structure:
          - pattern_name
          - doc_id
          - pattern_id
          - files_to_generate

    ground_truth_verification:
      - type: "data_structure"
        check: "generation_matrix has entries for all patterns"

    reporting:
      on_success: "Parsed {count} pattern specifications"
      on_failure: "Failed to parse specs: {error}"

  - step_id: "S2_generate_doc_id_values"
    description: "Generate RFC-compliant doc_id for patterns missing it"
    parallel: false
    actions:
      - action: "check_existing_doc_ids"
        source: "generation_matrix"

      - action: "generate_missing_doc_ids"
        algorithm: "pattern_id_to_doc_id"
        rules:
          - pattern: "^PAT-([A-Z-]+)-([0-9]+)$"
          - replacement: "DOC-$1-$2"
          - validation: "^[A-Z0-9]+(-[A-Z0-9]+)*$"

      - action: "validate_uniqueness"
        check: "no duplicate doc_id values"

    ground_truth_verification:
      - type: "format_check"
        pattern: "^DOC-[A-Z0-9-]+$"
        for_all: "doc_id values"

      - type: "uniqueness_check"
        check: "all doc_id values are unique"

    reporting:
      on_success: "Generated {count} doc_id values"
      on_failure: "doc_id generation failed: {error}"

  - step_id: "S3_batch_file_generation"
    description: "Generate files in parallel batches"
    parallel: true
    batch_size: 10
    parallel_batches: 3

    sub_steps:
      - sub_step_id: "S3.1_schemas"
        description: "Generate schema files"
        parallel: true
        actions:
          - action: "load_spec_inputs"
            source: "pattern_spec.inputs"

          - action: "generate_json_schema"
            template: "schema_template"
            add_properties:
              - doc_id
              - pattern_id
              - inputs
              - outputs

          - action: "write_schema_file"
            path: "patterns/schemas/{pattern_name}.schema.json"
            format: "json"
            indent: 2

        validation:
          - type: "json_syntax"
            command: "python -m json.tool {file}"

          - type: "schema_validation"
            check: "valid JSON Schema draft-07"

      - sub_step_id: "S3.2_examples"
        description: "Generate example instance files"
        parallel: true
        depends_on: "S3.1_schemas"
        actions:
          - action: "load_generated_schema"
            path: "patterns/schemas/{pattern_name}.schema.json"

          - action: "generate_minimal_instance"
            required_only: true
            output: "instance_minimal.json"

          - action: "generate_full_instance"
            all_properties: true
            output: "instance_full.json"

          - action: "generate_test_instance"
            test_values: true
            output: "instance_test.json"

          - action: "write_example_files"
            directory: "patterns/examples/{pattern_name}/"

        validation:
          - type: "schema_compliance"
            validate_against: "patterns/schemas/{pattern_name}.schema.json"

      - sub_step_id: "S3.3_executors"
        description: "Generate executor scaffold files"
        parallel: true
        actions:
          - action: "load_executor_template"
            template: "executor_template.ps1"

          - action: "inject_doc_link"
            header: "# DOC_LINK: {doc_id}"

          - action: "inject_metadata"
            fields:
              - pattern_name
              - pattern_id
              - version

          - action: "inject_parameter_block"
            parameters:
              - InstancePath

          - action: "write_executor_file"
            path: "patterns/executors/{pattern_name}_executor.ps1"

        validation:
          - type: "powershell_syntax"
            command: "powershell -NoProfile -Syntax -File {file}"

      - sub_step_id: "S3.4_tests"
        description: "Generate test scaffold files"
        parallel: true
        actions:
          - action: "load_test_template"
            template: "test_template.ps1"

          - action: "inject_doc_link"
            header: "# DOC_LINK: {doc_id}"

          - action: "inject_test_cases"
            cases:
              - executor_exists
              - parameter_validation
              - minimal_instance_execution
              - schema_validation

          - action: "write_test_file"
            path: "patterns/tests/test_{pattern_name}_executor.ps1"

        validation:
          - type: "pester_syntax"
            command: "Invoke-Pester -Path {file} -DryRun"

      - sub_step_id: "S3.5_sidecar_ids"
        description: "Generate schema sidecar ID files"
        parallel: true
        actions:
          - action: "create_sidecar_content"
            content:
              schema_path: "patterns/schemas/{pattern_name}.schema.json"
              doc_id: "{doc_id}"
              pattern_id: "{pattern_id}"
              role: "schema"
              linked_spec: "patterns/specs/{pattern_name}.pattern.yaml"

          - action: "write_sidecar_file"
            path: "patterns/schemas/{pattern_name}.schema.id.yaml"
            format: "yaml"

        validation:
          - type: "yaml_syntax"
            command: "python -c 'import yaml; yaml.safe_load(open(\"{file}\"))'"

    ground_truth_verification:
      - type: "file_count"
        check: "expected number of files generated"

      - type: "batch_validation"
        check: "all files in batch pass validation"

    reporting:
      on_success: "Batch {batch_num}: Generated {count} files"
      on_failure: "Batch {batch_num}: Failed {count} files"

  - step_id: "S4_update_existing_files"
    description: "Update existing files with doc_id"
    parallel: false
    strategy: "surgical_edits"

    actions:
      - action: "update_pattern_index"
        file: "patterns/registry/PATTERN_INDEX.yaml"
        operation: "add_field"
        field: "doc_id"
        values: "from generation_matrix"
        preserve_formatting: true

      - action: "update_spec_files"
        directory: "patterns/specs"
        operation: "add_field"
        field: "doc_id"
        position: "after_pattern_id"
        values: "from generation_matrix"

      - action: "update_executor_headers"
        directory: "patterns/executors"
        operation: "add_comment_header"
        header: "# DOC_LINK: {doc_id}"
        position: "top_of_file"

    ground_truth_verification:
      - type: "field_presence"
        check: "all files have doc_id field"

      - type: "value_consistency"
        check: "doc_id values match across artifacts"

    reporting:
      on_success: "Updated {count} existing files"
      on_failure: "Failed to update files: {error}"

  - step_id: "S5_generate_validation_scripts"
    description: "Generate validation and compliance scripts"
    parallel: false

    actions:
      - action: "generate_pattern_dir_check"
        source: "PAT-CHECK-001 requirements"
        output: "scripts/PATTERN_DIR_CHECK.ps1"
        implement:
          - directory_structure_check
          - file_existence_check
          - doc_id_consistency_check
          - schema_validation

      - action: "generate_doc_id_validator"
        source: "ID-SYSTEM-SPEC-V1"
        output: "scripts/validate_doc_id_consistency.ps1"
        implement:
          - format_validation
          - uniqueness_check
          - cross_artifact_linkage

      - action: "generate_test_infrastructure"
        output: "tests/patterns/"
        files:
          - __init__.py
          - test_pattern_registry.py
          - test_doc_id_compliance.py

    ground_truth_verification:
      - type: "script_executable"
        check: "scripts can be invoked"

      - type: "test_discoverable"
        check: "tests are discoverable by pytest"

    reporting:
      on_success: "Generated validation scripts"
      on_failure: "Validation script generation failed: {error}"

  - step_id: "S6_final_compliance_validation"
    description: "Run comprehensive compliance checks"
    parallel: false

    actions:
      - action: "run_pattern_dir_check"
        script: "scripts/PATTERN_DIR_CHECK.ps1"
        expect_exit_code: 0

      - action: "run_doc_id_validator"
        script: "scripts/validate_doc_id_consistency.ps1"
        expect_exit_code: 0

      - action: "validate_all_schemas"
        command: "python -m scripts.validate_all_schemas"
        expect: "all schemas valid"

      - action: "run_pattern_tests"
        command: "pytest tests/patterns/ -v"
        expect: "all tests pass"

    on_validation_failure:
      action: "generate_failure_report"
      output: "patterns/generation_failure_report.json"
      abort: true

    ground_truth_verification:
      - type: "compliance_check"
        requirement: "PAT-CHECK-001"
        status: "PASS"

      - type: "compliance_check"
        requirement: "ID-SYSTEM-SPEC-V1"
        status: "PASS"

    reporting:
      on_success: "✓ FULL COMPLIANCE - All validation passed"
      on_failure: "✗ COMPLIANCE FAILURE - See failure report"

ground_truth_criteria:
  required:
    - criterion: "all_files_generated"
      description: "All expected files exist in correct locations"
      verification: "file_system_check"

    - criterion: "all_validations_pass"
      description: "All syntax and schema validations pass"
      verification: "validation_results"

    - criterion: "doc_id_consistency"
      description: "doc_id values consistent across all artifacts"
      verification: "cross_artifact_check"

    - criterion: "pat_check_001_compliance"
      description: "Full compliance with PAT-CHECK-001"
      verification: "PATTERN_DIR_CHECK.ps1"

    - criterion: "id_system_spec_compliance"
      description: "Full compliance with ID-SYSTEM-SPEC-V1"
      verification: "validate_doc_id_consistency.ps1"

error_handling:
  - error_type: "batch_generation_failure"
    response: "retry_batch"
    max_attempts: 3

  - error_type: "validation_failure"
    response: "rollback_batch"
    preserve_logs: true

  - error_type: "compliance_failure"
    response: "abort"
    generate_report: true

performance_profile:
  estimated_time_manual: 180000  # 50 hours
  estimated_time_pattern: 9000   # 2.5 hours
  time_savings_seconds: 171000
  time_savings_percentage: "95%"

  files_generated: 128
  average_time_per_file: 70  # seconds

tool_bindings:
  powershell:
    invoke: "scripts/generate_all_pattern_files.ps1"

  python:
    invoke: "python scripts/generate_all_pattern_files.py"
